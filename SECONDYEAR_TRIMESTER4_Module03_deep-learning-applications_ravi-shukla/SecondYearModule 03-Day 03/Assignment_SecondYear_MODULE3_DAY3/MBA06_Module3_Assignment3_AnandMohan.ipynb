{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4LeLSOfxn7y"
      },
      "source": [
        "**Instantiating a small convnet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBBKuRWZxn8U"
      },
      "source": [
        "**Copying images to training, validation, and test directories**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpphSfi_yFp4",
        "outputId": "009a505b-937a-4d81-c0d4-56825df09c5e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq  '/content/drive/MyDrive/Colab_Notebooks/SECONDYEAR_TRIMESTER4_Module03_deep-learning-applications/DAY3_APPLICATION_OF_DEEP_LEARNING/Weather_dataset.zip'"
      ],
      "metadata": {
        "id": "K9UWCpk1SG3-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras import layers"
      ],
      "metadata": {
        "id": "g0_gxBZXR49p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Tov9MLExn8V"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co29KJbIxn8W"
      },
      "source": [
        "#FIRST APPROACH:**Instantiating a small convnet for dogs vs. cats classification**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvna_PCrxn8W"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5Ur0QxZxn8X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c15e3416-4d29-45f7-8934-2c73024100ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_24 (InputLayer)       [(None, 180, 180, 3)]     0         \n",
            "                                                                 \n",
            " rescaling_1 (Rescaling)     (None, 180, 180, 3)       0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 178, 178, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 89, 89, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 87, 87, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 43, 43, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 41, 41, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 20, 20, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 18, 18, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 9, 9, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 7, 7, 256)         590080    \n",
            "                                                                 \n",
            " flatten_16 (Flatten)        (None, 12544)             0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 4)                 50180     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,028,676\n",
            "Trainable params: 1,028,676\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4QVToVRxn8X"
      },
      "source": [
        "**Configuring the model for training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrhNpCyKxn8Y"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"sparse_categorical_accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzPBwo0rxn8Z"
      },
      "source": [
        "### Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os,shutil,pathlib\n",
        "base_dir=pathlib.Path(\"/content/Weather_dataset\")\n",
        "\n",
        "datagen=ImageDataGenerator(\n",
        "rescale=1./255,\n",
        "validation_split=0.2\n",
        ")\n",
        "\n",
        "train_dataset=datagen.flow_from_directory(\n",
        "directory= base_dir,\n",
        "subset='training',\n",
        "class_mode='sparse',\n",
        "target_size=(180,180),\n",
        "batch_size=32\n",
        ")\n",
        "\n",
        "validation_dataset=datagen.flow_from_directory(\n",
        "directory= base_dir,\n",
        "subset='validation',\n",
        "class_mode='sparse',\n",
        "target_size=(180,180),\n",
        "batch_size=32\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4wtL_2pa_fn",
        "outputId": "13c18638-468f-4dea-b29e-420ef1a60c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 901 images belonging to 4 classes.\n",
            "Found 224 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classnames=[k for k,v in train_dataset.class_indices.items()]\n",
        "print(\"classes:\",classnames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yse28SLuyA1",
        "outputId": "9b3c9ed6-d375-474f-ece2-a50689b088a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classes: ['cloudy', 'rain', 'shine', 'sunrise']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classnames=[k for k,v in validation_dataset.class_indices.items()]\n",
        "print(\"classes:\",classnames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JvvCBR6yCj7",
        "outputId": "18c5ef73-76df-418f-bc03-3655d18d7707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classes: ['cloudy', 'rain', 'shine', 'sunrise']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQmRCsR7xn8l"
      },
      "source": [
        "**Fitting the model using a `Dataset`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwMjIZVHxn8l"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "Wrjnf8jIYjrR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7918a6c-caf1-4b32-fb77-ecf95341e45e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "29/29 [==============================] - 9s 273ms/step - loss: 1.3810 - sparse_categorical_accuracy: 0.2997 - val_loss: 1.3692 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 2/30\n",
            "29/29 [==============================] - 7s 255ms/step - loss: 1.3740 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3679 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 3/30\n",
            "29/29 [==============================] - 7s 252ms/step - loss: 1.3766 - sparse_categorical_accuracy: 0.3152 - val_loss: 1.3693 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 4/30\n",
            "29/29 [==============================] - 9s 311ms/step - loss: 1.3763 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3724 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 5/30\n",
            "29/29 [==============================] - 7s 256ms/step - loss: 1.3616 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3742 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 6/30\n",
            "29/29 [==============================] - 7s 256ms/step - loss: 1.3598 - sparse_categorical_accuracy: 0.3219 - val_loss: 1.3785 - val_sparse_categorical_accuracy: 0.2679\n",
            "Epoch 7/30\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 1.3624 - sparse_categorical_accuracy: 0.2952 - val_loss: 1.3736 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 8/30\n",
            "29/29 [==============================] - 7s 253ms/step - loss: 1.3880 - sparse_categorical_accuracy: 0.2974 - val_loss: 1.3717 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 9/30\n",
            "29/29 [==============================] - 7s 253ms/step - loss: 1.3714 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3425 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 10/30\n",
            "29/29 [==============================] - 7s 257ms/step - loss: 1.3224 - sparse_categorical_accuracy: 0.3307 - val_loss: 1.3026 - val_sparse_categorical_accuracy: 0.5580\n",
            "Epoch 11/30\n",
            "29/29 [==============================] - 7s 252ms/step - loss: 1.3354 - sparse_categorical_accuracy: 0.3330 - val_loss: 1.3689 - val_sparse_categorical_accuracy: 0.3036\n",
            "Epoch 12/30\n",
            "29/29 [==============================] - 7s 255ms/step - loss: 1.3019 - sparse_categorical_accuracy: 0.3285 - val_loss: 1.3811 - val_sparse_categorical_accuracy: 0.2679\n",
            "Epoch 13/30\n",
            "29/29 [==============================] - 7s 259ms/step - loss: 1.3774 - sparse_categorical_accuracy: 0.2808 - val_loss: 1.3700 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 14/30\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 1.3721 - sparse_categorical_accuracy: 0.3762 - val_loss: 0.8746 - val_sparse_categorical_accuracy: 0.5491\n",
            "Epoch 15/30\n",
            "29/29 [==============================] - 7s 258ms/step - loss: 1.1468 - sparse_categorical_accuracy: 0.5105 - val_loss: 0.8455 - val_sparse_categorical_accuracy: 0.6562\n",
            "Epoch 16/30\n",
            "29/29 [==============================] - 7s 252ms/step - loss: 1.0123 - sparse_categorical_accuracy: 0.5416 - val_loss: 0.8191 - val_sparse_categorical_accuracy: 0.5536\n",
            "Epoch 17/30\n",
            "29/29 [==============================] - 8s 276ms/step - loss: 1.0145 - sparse_categorical_accuracy: 0.5472 - val_loss: 0.8169 - val_sparse_categorical_accuracy: 0.5491\n",
            "Epoch 18/30\n",
            "29/29 [==============================] - 7s 251ms/step - loss: 1.0508 - sparse_categorical_accuracy: 0.5294 - val_loss: 1.3268 - val_sparse_categorical_accuracy: 0.2545\n",
            "Epoch 19/30\n",
            "29/29 [==============================] - 7s 253ms/step - loss: 0.9283 - sparse_categorical_accuracy: 0.5694 - val_loss: 0.8179 - val_sparse_categorical_accuracy: 0.5536\n",
            "Epoch 20/30\n",
            "29/29 [==============================] - 7s 256ms/step - loss: 0.9974 - sparse_categorical_accuracy: 0.5538 - val_loss: 0.8931 - val_sparse_categorical_accuracy: 0.6116\n",
            "Epoch 21/30\n",
            "29/29 [==============================] - 7s 255ms/step - loss: 0.8943 - sparse_categorical_accuracy: 0.6149 - val_loss: 1.4133 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 22/30\n",
            "29/29 [==============================] - 7s 251ms/step - loss: 0.8689 - sparse_categorical_accuracy: 0.6448 - val_loss: 0.6276 - val_sparse_categorical_accuracy: 0.6964\n",
            "Epoch 23/30\n",
            "29/29 [==============================] - 7s 249ms/step - loss: 0.8155 - sparse_categorical_accuracy: 0.6504 - val_loss: 0.8507 - val_sparse_categorical_accuracy: 0.6786\n",
            "Epoch 24/30\n",
            "29/29 [==============================] - 7s 245ms/step - loss: 0.9221 - sparse_categorical_accuracy: 0.6238 - val_loss: 0.7632 - val_sparse_categorical_accuracy: 0.5982\n",
            "Epoch 25/30\n",
            "29/29 [==============================] - 7s 249ms/step - loss: 0.6169 - sparse_categorical_accuracy: 0.7492 - val_loss: 1.2661 - val_sparse_categorical_accuracy: 0.4821\n",
            "Epoch 26/30\n",
            "29/29 [==============================] - 7s 256ms/step - loss: 0.8604 - sparse_categorical_accuracy: 0.6659 - val_loss: 0.5761 - val_sparse_categorical_accuracy: 0.7679\n",
            "Epoch 27/30\n",
            "29/29 [==============================] - 9s 309ms/step - loss: 0.7643 - sparse_categorical_accuracy: 0.7059 - val_loss: 0.6292 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 28/30\n",
            "29/29 [==============================] - 7s 257ms/step - loss: 0.6153 - sparse_categorical_accuracy: 0.7514 - val_loss: 0.5340 - val_sparse_categorical_accuracy: 0.7723\n",
            "Epoch 29/30\n",
            "29/29 [==============================] - 7s 257ms/step - loss: 0.7001 - sparse_categorical_accuracy: 0.7081 - val_loss: 0.5676 - val_sparse_categorical_accuracy: 0.7589\n",
            "Epoch 30/30\n",
            "29/29 [==============================] - 7s 249ms/step - loss: 0.6817 - sparse_categorical_accuracy: 0.7347 - val_loss: 0.7895 - val_sparse_categorical_accuracy: 0.6830\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgcqFnnYxn8n"
      },
      "source": [
        "**Displaying curves of loss and accuracy during training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gy_hhl9pxn8n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "b3b964f9-ff86-411d-c62e-bc57ad069eec"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "accuracy = history.history[\"sparse_categorical_accuracy\"]\n",
        "val_accuracy = history.history[\"val_sparse_categorical_accuracy\"]\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChZbLOH3xn8o"
      },
      "source": [
        "**Evaluating the model on the test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUk62pkExn8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc92e266-abf4-40f1-fe7a-ced071f326d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 2s 258ms/step - loss: 0.5340 - sparse_categorical_accuracy: 0.7723\n",
            "Test accuracy: 0.772\n"
          ]
        }
      ],
      "source": [
        "test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(validation_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLEkIf1Kxn8q"
      },
      "source": [
        "#SECOND APPROACH:small convnet Using data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le63oEbWxn8r"
      },
      "source": [
        "**Define a data augmentation stage to add to an image model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0e1afJqxn8r"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj3R3EC1xn8u"
      },
      "source": [
        "**Defining a new convnet that includes image augmentation and dropout**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2KIa-RJxn8w"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"sparse_categorical_accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2J57Iwyxn8x"
      },
      "source": [
        "**Training the regularized convnet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YHS9UTAxn8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a57daab-e74c-499a-970c-dfdf4bc237c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "29/29 [==============================] - 10s 297ms/step - loss: 1.3764 - sparse_categorical_accuracy: 0.2997 - val_loss: 1.3687 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 8s 262ms/step - loss: 1.3720 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3718 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 8s 268ms/step - loss: 1.3748 - sparse_categorical_accuracy: 0.3119 - val_loss: 1.3694 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 8s 275ms/step - loss: 1.3717 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3687 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 8s 272ms/step - loss: 1.3708 - sparse_categorical_accuracy: 0.3185 - val_loss: 1.3201 - val_sparse_categorical_accuracy: 0.4911\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 8s 266ms/step - loss: 1.2903 - sparse_categorical_accuracy: 0.4129 - val_loss: 1.0235 - val_sparse_categorical_accuracy: 0.5580\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 8s 266ms/step - loss: 1.2655 - sparse_categorical_accuracy: 0.4528 - val_loss: 1.1089 - val_sparse_categorical_accuracy: 0.5268\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 8s 268ms/step - loss: 1.1261 - sparse_categorical_accuracy: 0.5061 - val_loss: 1.0048 - val_sparse_categorical_accuracy: 0.5089\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 8s 267ms/step - loss: 1.0804 - sparse_categorical_accuracy: 0.5272 - val_loss: 1.0835 - val_sparse_categorical_accuracy: 0.4554\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 8s 264ms/step - loss: 1.1099 - sparse_categorical_accuracy: 0.5461 - val_loss: 1.4621 - val_sparse_categorical_accuracy: 0.3438\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 8s 268ms/step - loss: 1.0477 - sparse_categorical_accuracy: 0.5339 - val_loss: 1.1896 - val_sparse_categorical_accuracy: 0.4509\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 8s 267ms/step - loss: 0.9564 - sparse_categorical_accuracy: 0.5849 - val_loss: 0.8557 - val_sparse_categorical_accuracy: 0.6920\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 8s 270ms/step - loss: 0.9616 - sparse_categorical_accuracy: 0.6104 - val_loss: 0.9347 - val_sparse_categorical_accuracy: 0.5893\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 8s 275ms/step - loss: 0.9401 - sparse_categorical_accuracy: 0.6193 - val_loss: 0.7836 - val_sparse_categorical_accuracy: 0.6920\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 8s 270ms/step - loss: 1.0198 - sparse_categorical_accuracy: 0.6304 - val_loss: 1.2204 - val_sparse_categorical_accuracy: 0.4152\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 8s 269ms/step - loss: 0.9064 - sparse_categorical_accuracy: 0.6504 - val_loss: 0.8273 - val_sparse_categorical_accuracy: 0.6384\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 8s 266ms/step - loss: 0.8685 - sparse_categorical_accuracy: 0.6393 - val_loss: 1.0160 - val_sparse_categorical_accuracy: 0.4821\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 8s 270ms/step - loss: 0.8117 - sparse_categorical_accuracy: 0.6815 - val_loss: 0.7000 - val_sparse_categorical_accuracy: 0.7188\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 8s 268ms/step - loss: 0.8698 - sparse_categorical_accuracy: 0.6626 - val_loss: 0.9547 - val_sparse_categorical_accuracy: 0.6161\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 8s 266ms/step - loss: 0.8101 - sparse_categorical_accuracy: 0.6837 - val_loss: 3.1268 - val_sparse_categorical_accuracy: 0.2232\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 8s 270ms/step - loss: 0.8616 - sparse_categorical_accuracy: 0.6826 - val_loss: 1.0925 - val_sparse_categorical_accuracy: 0.4866\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 8s 262ms/step - loss: 0.7190 - sparse_categorical_accuracy: 0.6926 - val_loss: 1.2384 - val_sparse_categorical_accuracy: 0.4688\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 9s 327ms/step - loss: 0.7999 - sparse_categorical_accuracy: 0.6837 - val_loss: 0.6496 - val_sparse_categorical_accuracy: 0.7321\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 8s 273ms/step - loss: 0.7230 - sparse_categorical_accuracy: 0.7181 - val_loss: 0.6412 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 8s 270ms/step - loss: 0.7883 - sparse_categorical_accuracy: 0.6859 - val_loss: 0.8044 - val_sparse_categorical_accuracy: 0.6830\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 8s 266ms/step - loss: 0.6606 - sparse_categorical_accuracy: 0.7603 - val_loss: 0.5980 - val_sparse_categorical_accuracy: 0.7679\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 8s 269ms/step - loss: 0.7714 - sparse_categorical_accuracy: 0.7325 - val_loss: 0.7167 - val_sparse_categorical_accuracy: 0.7054\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 8s 262ms/step - loss: 0.6879 - sparse_categorical_accuracy: 0.7536 - val_loss: 0.6074 - val_sparse_categorical_accuracy: 0.7723\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 8s 269ms/step - loss: 0.6378 - sparse_categorical_accuracy: 0.7259 - val_loss: 0.6334 - val_sparse_categorical_accuracy: 0.7366\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 8s 268ms/step - loss: 0.6450 - sparse_categorical_accuracy: 0.7536 - val_loss: 0.6012 - val_sparse_categorical_accuracy: 0.7679\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 8s 273ms/step - loss: 0.6234 - sparse_categorical_accuracy: 0.7481 - val_loss: 0.5526 - val_sparse_categorical_accuracy: 0.7768\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 8s 262ms/step - loss: 0.6197 - sparse_categorical_accuracy: 0.7669 - val_loss: 0.5556 - val_sparse_categorical_accuracy: 0.7589\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 8s 258ms/step - loss: 0.6064 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.6063 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 8s 267ms/step - loss: 0.6396 - sparse_categorical_accuracy: 0.7680 - val_loss: 0.9524 - val_sparse_categorical_accuracy: 0.6741\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 8s 267ms/step - loss: 0.5756 - sparse_categorical_accuracy: 0.7736 - val_loss: 1.1876 - val_sparse_categorical_accuracy: 0.5491\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 8s 255ms/step - loss: 0.5742 - sparse_categorical_accuracy: 0.7592 - val_loss: 0.5901 - val_sparse_categorical_accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 8s 270ms/step - loss: 0.5517 - sparse_categorical_accuracy: 0.7669 - val_loss: 2.3384 - val_sparse_categorical_accuracy: 0.4598\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - 8s 265ms/step - loss: 0.6575 - sparse_categorical_accuracy: 0.7669 - val_loss: 0.7835 - val_sparse_categorical_accuracy: 0.7009\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 8s 264ms/step - loss: 0.5511 - sparse_categorical_accuracy: 0.7847 - val_loss: 0.5678 - val_sparse_categorical_accuracy: 0.7589\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 8s 268ms/step - loss: 0.5665 - sparse_categorical_accuracy: 0.7714 - val_loss: 1.2602 - val_sparse_categorical_accuracy: 0.5982\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 8s 261ms/step - loss: 0.5818 - sparse_categorical_accuracy: 0.7458 - val_loss: 0.8153 - val_sparse_categorical_accuracy: 0.6384\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 8s 271ms/step - loss: 0.6554 - sparse_categorical_accuracy: 0.7714 - val_loss: 0.5510 - val_sparse_categorical_accuracy: 0.7946\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 9s 304ms/step - loss: 0.5358 - sparse_categorical_accuracy: 0.7925 - val_loss: 1.0465 - val_sparse_categorical_accuracy: 0.6250\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 8s 283ms/step - loss: 0.6457 - sparse_categorical_accuracy: 0.7780 - val_loss: 0.6349 - val_sparse_categorical_accuracy: 0.7188\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - 8s 265ms/step - loss: 0.4961 - sparse_categorical_accuracy: 0.7969 - val_loss: 1.2050 - val_sparse_categorical_accuracy: 0.5536\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 8s 269ms/step - loss: 0.5344 - sparse_categorical_accuracy: 0.7936 - val_loss: 0.6072 - val_sparse_categorical_accuracy: 0.7411\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 8s 266ms/step - loss: 0.5175 - sparse_categorical_accuracy: 0.7858 - val_loss: 0.7087 - val_sparse_categorical_accuracy: 0.7143\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - 8s 267ms/step - loss: 0.5508 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.7046 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 49/100\n",
            "29/29 [==============================] - 8s 267ms/step - loss: 0.5168 - sparse_categorical_accuracy: 0.7802 - val_loss: 0.6204 - val_sparse_categorical_accuracy: 0.7500\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - 8s 265ms/step - loss: 0.5356 - sparse_categorical_accuracy: 0.7802 - val_loss: 0.5976 - val_sparse_categorical_accuracy: 0.7634\n",
            "Epoch 51/100\n",
            "29/29 [==============================] - 8s 262ms/step - loss: 0.5457 - sparse_categorical_accuracy: 0.7869 - val_loss: 0.7802 - val_sparse_categorical_accuracy: 0.7009\n",
            "Epoch 52/100\n",
            "29/29 [==============================] - 8s 271ms/step - loss: 0.5353 - sparse_categorical_accuracy: 0.7902 - val_loss: 0.6510 - val_sparse_categorical_accuracy: 0.7723\n",
            "Epoch 53/100\n",
            "29/29 [==============================] - 8s 272ms/step - loss: 0.5374 - sparse_categorical_accuracy: 0.7825 - val_loss: 0.9012 - val_sparse_categorical_accuracy: 0.6562\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - 8s 269ms/step - loss: 0.4948 - sparse_categorical_accuracy: 0.7847 - val_loss: 0.5737 - val_sparse_categorical_accuracy: 0.7634\n",
            "Epoch 55/100\n",
            "29/29 [==============================] - 8s 270ms/step - loss: 0.5369 - sparse_categorical_accuracy: 0.7703 - val_loss: 0.6278 - val_sparse_categorical_accuracy: 0.7679\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - 8s 268ms/step - loss: 0.5020 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.8636 - val_sparse_categorical_accuracy: 0.6830\n",
            "Epoch 57/100\n",
            "29/29 [==============================] - 8s 274ms/step - loss: 0.5519 - sparse_categorical_accuracy: 0.8047 - val_loss: 0.7036 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 58/100\n",
            "29/29 [==============================] - 8s 273ms/step - loss: 0.4700 - sparse_categorical_accuracy: 0.8036 - val_loss: 0.5567 - val_sparse_categorical_accuracy: 0.7768\n",
            "Epoch 59/100\n",
            "29/29 [==============================] - 8s 272ms/step - loss: 0.5194 - sparse_categorical_accuracy: 0.8036 - val_loss: 0.5600 - val_sparse_categorical_accuracy: 0.7679\n",
            "Epoch 60/100\n",
            "29/29 [==============================] - 8s 259ms/step - loss: 0.5031 - sparse_categorical_accuracy: 0.8069 - val_loss: 0.5839 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 61/100\n",
            "29/29 [==============================] - 8s 270ms/step - loss: 0.5173 - sparse_categorical_accuracy: 0.7947 - val_loss: 0.8665 - val_sparse_categorical_accuracy: 0.7009\n",
            "Epoch 62/100\n",
            "29/29 [==============================] - 8s 275ms/step - loss: 0.4758 - sparse_categorical_accuracy: 0.8257 - val_loss: 0.5688 - val_sparse_categorical_accuracy: 0.7679\n",
            "Epoch 63/100\n",
            "29/29 [==============================] - 8s 275ms/step - loss: 0.5033 - sparse_categorical_accuracy: 0.7814 - val_loss: 0.5103 - val_sparse_categorical_accuracy: 0.8036\n",
            "Epoch 64/100\n",
            "29/29 [==============================] - 8s 269ms/step - loss: 0.5133 - sparse_categorical_accuracy: 0.7913 - val_loss: 0.5582 - val_sparse_categorical_accuracy: 0.7946\n",
            "Epoch 65/100\n",
            "29/29 [==============================] - 8s 276ms/step - loss: 0.4808 - sparse_categorical_accuracy: 0.7969 - val_loss: 0.8073 - val_sparse_categorical_accuracy: 0.7589\n",
            "Epoch 66/100\n",
            "29/29 [==============================] - 9s 322ms/step - loss: 0.5379 - sparse_categorical_accuracy: 0.7869 - val_loss: 0.5289 - val_sparse_categorical_accuracy: 0.7812\n",
            "Epoch 67/100\n",
            "29/29 [==============================] - 8s 283ms/step - loss: 0.4735 - sparse_categorical_accuracy: 0.8224 - val_loss: 0.5496 - val_sparse_categorical_accuracy: 0.7812\n",
            "Epoch 68/100\n",
            "29/29 [==============================] - 8s 267ms/step - loss: 0.4454 - sparse_categorical_accuracy: 0.8091 - val_loss: 0.6712 - val_sparse_categorical_accuracy: 0.7277\n",
            "Epoch 69/100\n",
            "29/29 [==============================] - 8s 268ms/step - loss: 0.5298 - sparse_categorical_accuracy: 0.7969 - val_loss: 0.5398 - val_sparse_categorical_accuracy: 0.7902\n",
            "Epoch 70/100\n",
            "29/29 [==============================] - 8s 268ms/step - loss: 0.4909 - sparse_categorical_accuracy: 0.7969 - val_loss: 0.5540 - val_sparse_categorical_accuracy: 0.7768\n",
            "Epoch 71/100\n",
            "29/29 [==============================] - 8s 271ms/step - loss: 0.4736 - sparse_categorical_accuracy: 0.8113 - val_loss: 0.7565 - val_sparse_categorical_accuracy: 0.6830\n",
            "Epoch 72/100\n",
            "29/29 [==============================] - 8s 267ms/step - loss: 0.4686 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.5245 - val_sparse_categorical_accuracy: 0.7857\n",
            "Epoch 73/100\n",
            "29/29 [==============================] - 8s 266ms/step - loss: 0.5402 - sparse_categorical_accuracy: 0.7869 - val_loss: 0.6371 - val_sparse_categorical_accuracy: 0.7589\n",
            "Epoch 74/100\n",
            "29/29 [==============================] - 8s 264ms/step - loss: 0.4703 - sparse_categorical_accuracy: 0.7980 - val_loss: 0.7682 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 75/100\n",
            "29/29 [==============================] - 8s 268ms/step - loss: 0.4800 - sparse_categorical_accuracy: 0.8024 - val_loss: 0.4909 - val_sparse_categorical_accuracy: 0.8036\n",
            "Epoch 76/100\n",
            "29/29 [==============================] - 8s 267ms/step - loss: 0.4471 - sparse_categorical_accuracy: 0.8213 - val_loss: 0.5239 - val_sparse_categorical_accuracy: 0.7902\n",
            "Epoch 77/100\n",
            "29/29 [==============================] - 8s 268ms/step - loss: 0.4606 - sparse_categorical_accuracy: 0.8147 - val_loss: 0.6309 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 78/100\n",
            "29/29 [==============================] - 8s 265ms/step - loss: 0.5110 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.7305 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 79/100\n",
            "29/29 [==============================] - 8s 272ms/step - loss: 0.4389 - sparse_categorical_accuracy: 0.8280 - val_loss: 0.6460 - val_sparse_categorical_accuracy: 0.7411\n",
            "Epoch 80/100\n",
            "29/29 [==============================] - 8s 268ms/step - loss: 0.4820 - sparse_categorical_accuracy: 0.8213 - val_loss: 0.5081 - val_sparse_categorical_accuracy: 0.7902\n",
            "Epoch 81/100\n",
            "29/29 [==============================] - 8s 265ms/step - loss: 0.4669 - sparse_categorical_accuracy: 0.8047 - val_loss: 0.5917 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 82/100\n",
            "29/29 [==============================] - 8s 276ms/step - loss: 0.4182 - sparse_categorical_accuracy: 0.8291 - val_loss: 0.5835 - val_sparse_categorical_accuracy: 0.7768\n",
            "Epoch 83/100\n",
            "29/29 [==============================] - 8s 272ms/step - loss: 0.4555 - sparse_categorical_accuracy: 0.8280 - val_loss: 0.5249 - val_sparse_categorical_accuracy: 0.7857\n",
            "Epoch 84/100\n",
            "29/29 [==============================] - 8s 272ms/step - loss: 0.4721 - sparse_categorical_accuracy: 0.8147 - val_loss: 0.4986 - val_sparse_categorical_accuracy: 0.7946\n",
            "Epoch 85/100\n",
            "29/29 [==============================] - 8s 258ms/step - loss: 0.4588 - sparse_categorical_accuracy: 0.8069 - val_loss: 0.6894 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 86/100\n",
            "29/29 [==============================] - 8s 263ms/step - loss: 0.5055 - sparse_categorical_accuracy: 0.8091 - val_loss: 0.4957 - val_sparse_categorical_accuracy: 0.7946\n",
            "Epoch 87/100\n",
            "29/29 [==============================] - 8s 263ms/step - loss: 0.4367 - sparse_categorical_accuracy: 0.8202 - val_loss: 0.5708 - val_sparse_categorical_accuracy: 0.7946\n",
            "Epoch 88/100\n",
            "29/29 [==============================] - 8s 269ms/step - loss: 0.4802 - sparse_categorical_accuracy: 0.8036 - val_loss: 0.4869 - val_sparse_categorical_accuracy: 0.8125\n",
            "Epoch 89/100\n",
            "29/29 [==============================] - 8s 272ms/step - loss: 0.4477 - sparse_categorical_accuracy: 0.8113 - val_loss: 0.5346 - val_sparse_categorical_accuracy: 0.7991\n",
            "Epoch 90/100\n",
            "29/29 [==============================] - 8s 271ms/step - loss: 0.4423 - sparse_categorical_accuracy: 0.8191 - val_loss: 0.8439 - val_sparse_categorical_accuracy: 0.6920\n",
            "Epoch 91/100\n",
            "29/29 [==============================] - 9s 324ms/step - loss: 0.4168 - sparse_categorical_accuracy: 0.8368 - val_loss: 0.5539 - val_sparse_categorical_accuracy: 0.7991\n",
            "Epoch 92/100\n",
            "29/29 [==============================] - 8s 266ms/step - loss: 0.4198 - sparse_categorical_accuracy: 0.8291 - val_loss: 0.5260 - val_sparse_categorical_accuracy: 0.7991\n",
            "Epoch 93/100\n",
            "29/29 [==============================] - 8s 264ms/step - loss: 0.4327 - sparse_categorical_accuracy: 0.8335 - val_loss: 0.5405 - val_sparse_categorical_accuracy: 0.7366\n",
            "Epoch 94/100\n",
            "29/29 [==============================] - 8s 264ms/step - loss: 0.4444 - sparse_categorical_accuracy: 0.8213 - val_loss: 0.6584 - val_sparse_categorical_accuracy: 0.7812\n",
            "Epoch 95/100\n",
            "29/29 [==============================] - 8s 262ms/step - loss: 0.4212 - sparse_categorical_accuracy: 0.8280 - val_loss: 0.6336 - val_sparse_categorical_accuracy: 0.7723\n",
            "Epoch 96/100\n",
            "29/29 [==============================] - 8s 261ms/step - loss: 0.4226 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.6487 - val_sparse_categorical_accuracy: 0.7366\n",
            "Epoch 97/100\n",
            "29/29 [==============================] - 8s 272ms/step - loss: 0.4367 - sparse_categorical_accuracy: 0.8257 - val_loss: 0.6031 - val_sparse_categorical_accuracy: 0.7679\n",
            "Epoch 98/100\n",
            "29/29 [==============================] - 8s 267ms/step - loss: 0.4631 - sparse_categorical_accuracy: 0.8147 - val_loss: 0.5762 - val_sparse_categorical_accuracy: 0.7946\n",
            "Epoch 99/100\n",
            "29/29 [==============================] - 8s 264ms/step - loss: 0.3541 - sparse_categorical_accuracy: 0.8535 - val_loss: 0.6743 - val_sparse_categorical_accuracy: 0.7366\n",
            "Epoch 100/100\n",
            "29/29 [==============================] - 8s 265ms/step - loss: 0.4353 - sparse_categorical_accuracy: 0.8313 - val_loss: 0.6100 - val_sparse_categorical_accuracy: 0.7723\n"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch_with_augmentation.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=100,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oaxr6DI0xn8y"
      },
      "source": [
        "**Evaluating the model on the test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlOz5xsnxn8z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "341419ad-4d4d-4007-ee76-67a50e9a2f3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 2s 242ms/step - loss: 0.4869 - sparse_categorical_accuracy: 0.8125\n",
            "Test accuracy: 0.812\n"
          ]
        }
      ],
      "source": [
        "test_model = keras.models.load_model(\n",
        "    \"convnet_from_scratch_with_augmentation.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(validation_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aefd_KZxxn80"
      },
      "source": [
        "## Leveraging a pretrained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUmUvSYhxn80"
      },
      "source": [
        "#THIRD APPROACH: Feature extraction with a pretrained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUhBjR4Txn81"
      },
      "source": [
        "**Instantiating the VGG16 convolutional base**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16\n",
        "conv_base = VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(180,180, 3))"
      ],
      "metadata": {
        "id": "Uio6t47CTvWT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7623ac4-b83f-49cd-aac3-db078c5daf8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zemWAktTxn82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ae4a632-4b14-4145-e173-402374547a4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 180, 180, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 180, 180, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 180, 180, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 90, 90, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 90, 90, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 90, 90, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 45, 45, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 45, 45, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 45, 45, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 45, 45, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 22, 22, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 22, 22, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 22, 22, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 22, 22, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 11, 11, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 5, 5, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "conv_base.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcY1O4_9xn83"
      },
      "source": [
        "#### Fast feature extraction without data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHae7SM2xn84"
      },
      "source": [
        "**Extracting the VGG16 features and corresponding labels**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "batch_size=32\n",
        "def get_features_and_labels(dataset,sample_count):\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "    i=0\n",
        "    for images, labels in dataset:\n",
        "        preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n",
        "        features = conv_base.predict(preprocessed_images)\n",
        "        all_features.append(features)\n",
        "        all_labels.append(labels)\n",
        "        i=i+1\n",
        "        if i  >= sample_count:\n",
        "          break\n",
        "    return np.concatenate(all_features), np.concatenate(all_labels)\n",
        "\n",
        "train_features, train_labels =  get_features_and_labels(train_dataset,901)\n",
        "print(\"train_features and labels collected\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUm6MS5UZwmF",
        "outputId": "1f514df0-bb0d-4907-df77-d68f8ca3d0a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 162ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "train_features and labels collected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_features, val_labels =  get_features_and_labels(validation_dataset,224)\n",
        "print(\"val_features and labels collected\")"
      ],
      "metadata": {
        "id": "lxhvsuc6aiN-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "036258c9-f284-4bce-9d30-1e7dc41e9fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "val_features and labels collected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoGJP3XSeqda",
        "outputId": "88748243-a834-4443-dcc3-92943ba3e26f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27995, 5, 5, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnOO7kssxn86"
      },
      "source": [
        "**Defining and training the densely connected classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8m7v05ACxn87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc8df8b-684e-48b5-ca66-db277b38334f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "875/875 [==============================] - 5s 5ms/step - loss: 2.7588 - sparse_categorical_accuracy: 0.3048 - val_loss: 1.3688 - val_sparse_categorical_accuracy: 0.3527\n",
            "Epoch 2/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 1.3276 - sparse_categorical_accuracy: 0.3707 - val_loss: 1.4076 - val_sparse_categorical_accuracy: 0.3482\n",
            "Epoch 3/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 1.2662 - sparse_categorical_accuracy: 0.4231 - val_loss: 1.2224 - val_sparse_categorical_accuracy: 0.4688\n",
            "Epoch 4/50\n",
            "875/875 [==============================] - 5s 6ms/step - loss: 1.2183 - sparse_categorical_accuracy: 0.4550 - val_loss: 1.8820 - val_sparse_categorical_accuracy: 0.2679\n",
            "Epoch 5/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 1.1845 - sparse_categorical_accuracy: 0.4753 - val_loss: 1.2792 - val_sparse_categorical_accuracy: 0.4509\n",
            "Epoch 6/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 1.1554 - sparse_categorical_accuracy: 0.4986 - val_loss: 1.2942 - val_sparse_categorical_accuracy: 0.4018\n",
            "Epoch 7/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 1.1349 - sparse_categorical_accuracy: 0.5079 - val_loss: 1.2592 - val_sparse_categorical_accuracy: 0.4330\n",
            "Epoch 8/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 1.1050 - sparse_categorical_accuracy: 0.5281 - val_loss: 1.9466 - val_sparse_categorical_accuracy: 0.2679\n",
            "Epoch 9/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 1.0850 - sparse_categorical_accuracy: 0.5346 - val_loss: 1.2375 - val_sparse_categorical_accuracy: 0.5179\n",
            "Epoch 10/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 1.0694 - sparse_categorical_accuracy: 0.5451 - val_loss: 1.4120 - val_sparse_categorical_accuracy: 0.3973\n",
            "Epoch 11/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 1.0553 - sparse_categorical_accuracy: 0.5566 - val_loss: 1.1635 - val_sparse_categorical_accuracy: 0.5179\n",
            "Epoch 12/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 1.0369 - sparse_categorical_accuracy: 0.5624 - val_loss: 1.2746 - val_sparse_categorical_accuracy: 0.4643\n",
            "Epoch 13/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 1.0275 - sparse_categorical_accuracy: 0.5674 - val_loss: 1.2586 - val_sparse_categorical_accuracy: 0.4866\n",
            "Epoch 14/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 1.0179 - sparse_categorical_accuracy: 0.5720 - val_loss: 1.1719 - val_sparse_categorical_accuracy: 0.5045\n",
            "Epoch 15/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 1.0076 - sparse_categorical_accuracy: 0.5790 - val_loss: 1.3877 - val_sparse_categorical_accuracy: 0.4732\n",
            "Epoch 16/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 1.0004 - sparse_categorical_accuracy: 0.5836 - val_loss: 1.1735 - val_sparse_categorical_accuracy: 0.5446\n",
            "Epoch 17/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.9891 - sparse_categorical_accuracy: 0.5870 - val_loss: 1.9293 - val_sparse_categorical_accuracy: 0.3036\n",
            "Epoch 18/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.9804 - sparse_categorical_accuracy: 0.5965 - val_loss: 1.3040 - val_sparse_categorical_accuracy: 0.4375\n",
            "Epoch 19/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.9696 - sparse_categorical_accuracy: 0.5989 - val_loss: 1.3258 - val_sparse_categorical_accuracy: 0.4866\n",
            "Epoch 20/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.9594 - sparse_categorical_accuracy: 0.6010 - val_loss: 1.1673 - val_sparse_categorical_accuracy: 0.5446\n",
            "Epoch 21/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.9605 - sparse_categorical_accuracy: 0.6043 - val_loss: 1.4601 - val_sparse_categorical_accuracy: 0.4018\n",
            "Epoch 22/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.9473 - sparse_categorical_accuracy: 0.6087 - val_loss: 1.4148 - val_sparse_categorical_accuracy: 0.5223\n",
            "Epoch 23/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.9416 - sparse_categorical_accuracy: 0.6129 - val_loss: 1.3559 - val_sparse_categorical_accuracy: 0.4375\n",
            "Epoch 24/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.9280 - sparse_categorical_accuracy: 0.6192 - val_loss: 1.2054 - val_sparse_categorical_accuracy: 0.5179\n",
            "Epoch 25/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.9255 - sparse_categorical_accuracy: 0.6215 - val_loss: 1.1847 - val_sparse_categorical_accuracy: 0.5268\n",
            "Epoch 26/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.9190 - sparse_categorical_accuracy: 0.6224 - val_loss: 1.2196 - val_sparse_categorical_accuracy: 0.5580\n",
            "Epoch 27/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.9178 - sparse_categorical_accuracy: 0.6264 - val_loss: 1.3093 - val_sparse_categorical_accuracy: 0.5402\n",
            "Epoch 28/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.9074 - sparse_categorical_accuracy: 0.6288 - val_loss: 1.8249 - val_sparse_categorical_accuracy: 0.4777\n",
            "Epoch 29/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.9117 - sparse_categorical_accuracy: 0.6274 - val_loss: 1.0832 - val_sparse_categorical_accuracy: 0.5848\n",
            "Epoch 30/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.8955 - sparse_categorical_accuracy: 0.6356 - val_loss: 1.5758 - val_sparse_categorical_accuracy: 0.4062\n",
            "Epoch 31/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.8944 - sparse_categorical_accuracy: 0.6369 - val_loss: 1.2013 - val_sparse_categorical_accuracy: 0.5491\n",
            "Epoch 32/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.8836 - sparse_categorical_accuracy: 0.6402 - val_loss: 1.5988 - val_sparse_categorical_accuracy: 0.4375\n",
            "Epoch 33/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.8870 - sparse_categorical_accuracy: 0.6396 - val_loss: 1.1219 - val_sparse_categorical_accuracy: 0.5938\n",
            "Epoch 34/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.8759 - sparse_categorical_accuracy: 0.6444 - val_loss: 1.2541 - val_sparse_categorical_accuracy: 0.5804\n",
            "Epoch 35/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.8764 - sparse_categorical_accuracy: 0.6419 - val_loss: 1.2496 - val_sparse_categorical_accuracy: 0.5446\n",
            "Epoch 36/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.8738 - sparse_categorical_accuracy: 0.6443 - val_loss: 1.3111 - val_sparse_categorical_accuracy: 0.5446\n",
            "Epoch 37/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.8635 - sparse_categorical_accuracy: 0.6504 - val_loss: 1.3490 - val_sparse_categorical_accuracy: 0.5000\n",
            "Epoch 38/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.8616 - sparse_categorical_accuracy: 0.6502 - val_loss: 1.2730 - val_sparse_categorical_accuracy: 0.5491\n",
            "Epoch 39/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.8611 - sparse_categorical_accuracy: 0.6513 - val_loss: 1.2535 - val_sparse_categorical_accuracy: 0.5446\n",
            "Epoch 40/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.8507 - sparse_categorical_accuracy: 0.6572 - val_loss: 1.2591 - val_sparse_categorical_accuracy: 0.5804\n",
            "Epoch 41/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.8509 - sparse_categorical_accuracy: 0.6559 - val_loss: 1.3234 - val_sparse_categorical_accuracy: 0.5223\n",
            "Epoch 42/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.8455 - sparse_categorical_accuracy: 0.6609 - val_loss: 1.1945 - val_sparse_categorical_accuracy: 0.5893\n",
            "Epoch 43/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.8417 - sparse_categorical_accuracy: 0.6615 - val_loss: 1.1590 - val_sparse_categorical_accuracy: 0.6161\n",
            "Epoch 44/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.8367 - sparse_categorical_accuracy: 0.6645 - val_loss: 1.5999 - val_sparse_categorical_accuracy: 0.4777\n",
            "Epoch 45/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.8377 - sparse_categorical_accuracy: 0.6648 - val_loss: 1.1308 - val_sparse_categorical_accuracy: 0.6161\n",
            "Epoch 46/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.8238 - sparse_categorical_accuracy: 0.6673 - val_loss: 2.4645 - val_sparse_categorical_accuracy: 0.2946\n",
            "Epoch 47/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.8325 - sparse_categorical_accuracy: 0.6643 - val_loss: 1.3671 - val_sparse_categorical_accuracy: 0.5134\n",
            "Epoch 48/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.8219 - sparse_categorical_accuracy: 0.6708 - val_loss: 1.2519 - val_sparse_categorical_accuracy: 0.5938\n",
            "Epoch 49/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.8194 - sparse_categorical_accuracy: 0.6685 - val_loss: 1.3335 - val_sparse_categorical_accuracy: 0.5268\n",
            "Epoch 50/50\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.8221 - sparse_categorical_accuracy: 0.6723 - val_loss: 1.2805 - val_sparse_categorical_accuracy: 0.5580\n"
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(5, 5, 512))\n",
        "x = layers.Flatten()(inputs)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"sparse_categorical_accuracy\"])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "      filepath=\"feature_extraction.keras\",\n",
        "      save_best_only=True,\n",
        "      monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_features, train_labels,\n",
        "    epochs=50,\n",
        "    validation_data=(val_features, val_labels),\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = keras.models.load_model(\n",
        "    \"feature_extraction.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(val_features, val_labels)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tbAcntafyuJ",
        "outputId": "f0e55c37-b088-429e-c0d9-83e5e272c42d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "224/224 [==============================] - 1s 3ms/step - loss: 1.0832 - sparse_categorical_accuracy: 0.5848\n",
            "Test accuracy: 0.585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYylK6ewxn88"
      },
      "source": [
        "**Plotting the results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYZ5svLgxn88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "0b312ea9-6bcb-47fc-f9f1-c01965d0d2fd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2deXgV1fnHvy8BZIssISAQIKACyhYggIqyaGtBUURxQapQVITSiktLUYuglao/bau0LqWKqCBoXahWUECxgFQhICprAQ2LsoSwJQSQJO/vj3cOd3Jz5965W27u5P08z33mzpkzM2fm3vnOe97znnOImaEoiqJ4l2qJLoCiKIoSX1ToFUVRPI4KvaIoisdRoVcURfE4KvSKoigeR4VeURTF46jQK2FBRAuJaGSs8yYSIsolop/E4bhMROdY318goslu8kZwnhFEtCjScgY5bn8i2h3r4yoVT/VEF0CJP0RUaFutA+AkgBJr/U5mnuP2WMw8KB55vQ4zj43FcYgoE8B3AGowc7F17DkAXP+GStVDhb4KwMz1zHciygVwOzMv8c9HRNWNeCiK4h3UdVOFMVVzIvodEe0F8DIRNSSifxNRHhEdsr5n2Pb5lIhut76PIqIVRPSUlfc7IhoUYd42RLSMiAqIaAkRPUtEsx3K7aaMfyCiz6zjLSKixrbttxDRDiLKJ6IHg9yf3kS0l4hSbGlDiehr63svIvovER0moj1E9DciqulwrFlE9Kht/bfWPj8Q0Wi/vFcS0ZdEdJSIdhHRVNvmZdbyMBEVEtGF5t7a9r+IiFYT0RFreZHbexMMIjrP2v8wEW0goqtt264goo3WMb8not9Y6Y2t3+cwER0kouVEpLpTwegNV84C0AhAawBjIP+Jl631VgCOA/hbkP17A9gCoDGA/wPwEhFRBHlfB7AKQBqAqQBuCXJON2W8GcAvADQBUBOAEZ7zATxvHb+5db4MBICZvwBwDMClfsd93fpeAuAe63ouBHAZgF8GKTesMgy0yvNTAOcC8G8fOAbgVgANAFwJYBwRXWNt62stGzBzPWb+r9+xGwH4AMB069r+DOADIkrzu4Zy9yZEmWsAeB/AImu/XwOYQ0TtrSwvQdyAqQA6AfjESr8PwG4A6QCaAngAgI67UsGo0CulAKYw80lmPs7M+cz8NjMXMXMBgGkA+gXZfwcz/4OZSwC8AqAZ5IF2nZeIWgHoCeAhZv6RmVcAeM/phC7L+DIz/4+ZjwN4E0CWlT4MwL+ZeRkznwQw2boHTswFMBwAiCgVwBVWGph5DTN/zszFzJwL4O8ByhGIG6zyrWfmY5AXm/36PmXmb5i5lJm/ts7n5riAvBi2MvNrVrnmAtgM4CpbHqd7E4wLANQD8Lj1G30C4N+w7g2AUwDOJ6IzmfkQM6+1pTcD0JqZTzHzctYBtiocFXolj5lPmBUiqkNEf7dcG0chroIGdveFH3vNF2Yusr7WCzNvcwAHbWkAsMupwC7LuNf2vchWpub2Y1tCm+90Loj1fi0RnQHgWgBrmXmHVY52lltir1WOP0Ks+1CUKQOAHX7X15uIllquqSMAxro8rjn2Dr+0HQBa2Nad7k3IMjOz/aVoP+51kJfgDiL6DxFdaKU/CWAbgEVE9C0RTXJ3GUosUaFX/K2r+wC0B9Cbmc+Ez1Xg5I6JBXsANCKiOra0lkHyR1PGPfZjW+dMc8rMzBshgjYIZd02gLiANgM41yrHA5GUAeJ+svM6pEbTkpnrA3jBdtxQ1vAPEJeWnVYAvndRrlDHbennXz99XGZezcxDIG6d+ZCaApi5gJnvY+a2AK4GcC8RXRZlWZQwUaFX/EmF+LwPW/7eKfE+oWUh5wCYSkQ1LWvwqiC7RFPGtwAMJqKLrYbTRxD6OXgdwATIC+WffuU4CqCQiDoAGOeyDG8CGEVE51svGv/yp0JqOCeIqBfkBWPIg7ia2jocewGAdkR0MxFVJ6IbAZwPcbNEwxcQ638iEdUgov6Q32ie9ZuNIKL6zHwKck9KAYCIBhPROVZbzBFIu0YwV5kSB1ToFX+eBlAbwAEAnwP4sILOOwLSoJkP4FEAb0Di/QMRcRmZeQOA8RDx3gPgEKSxMBjGR/4JMx+wpf8GIsIFAP5hldlNGRZa1/AJxK3xiV+WXwJ4hIgKADwEyzq29i2CtEl8ZkWyXOB37HwAgyG1nnwAEwEM9it32DDzjxBhHwS5788BuJWZN1tZbgGQa7mwxkJ+T0Aam5cAKATwXwDPMfPSaMqihA9pu4hSGSGiNwBsZua41ygUxeuoRa9UCoioJxGdTUTVrPDDIRBfr6IoUaI9Y5XKwlkA3oE0jO4GMI6Zv0xskRTFG6jrRlEUxeOo60ZRFMXjVErXTePGjTkzMzPRxVAURUka1qxZc4CZ0wNtq5RCn5mZiZycnEQXQ1EUJWkgIv8e0adR142iKIrHUaFXFEXxOCr0iqIoHqdS+ugVRalYTp06hd27d+PEiROhMysJpVatWsjIyECNGjVc76NCrygKdu/ejdTUVGRmZsJ53hgl0TAz8vPzsXv3brRp08b1fp5x3cyZA2RmAtWqyXKOTpWsKK45ceIE0tLSVOQrOUSEtLS0sGteIS16ImoJ4FXIrEEMYAYzP+OX57fwjVZXHcB5ANKZ+SDJZNQFkOFJi5k5O6wSumDOHGDMGKDImrZixw5ZB4ARI5z3UxTFh4p8chDJ7+TGoi8GcB8znw+ZTmy8Ne/maZj5SWbOYuYsAPcD+A8zH7RlGWBtj7nIA8CDD/pE3lBUJOmKoihVnZBCz8x7zPyP1vycm1B2WjJ/hsOaU7Oi2LkzvHRFUSoX+fn5yMrKQlZWFs466yy0aNHi9PqPP/4YdN+cnBzcddddIc9x0UUXxaSsn376KQYPHhyTY1UUYfnoiSgTQDfIbDOBttcBMBDA27ZkhswXuYaIxgQ59hgiyiGinLy8vHCKhVb+E7GFSFcUJTpi3SaWlpaGdevWYd26dRg7dizuueee0+s1a9ZEcXGx477Z2dmYPn16yHOsXLkyukImMa6FnojqQQT8bmY+6pDtKgCf+bltLmbm7pCZacYTUd9AOzLzDGbOZubs9PSAwzU4Mm0aUKdO2bQ6dSRdUZTYYtrEduwAmH1tYrEOgBg1ahTGjh2L3r17Y+LEiVi1ahUuvPBCdOvWDRdddBG2bNkCoKyFPXXqVIwePRr9+/dH27Zty7wA6tWrdzp///79MWzYMHTo0AEjRoyAGcV3wYIF6NChA3r06IG77rorpOV+8OBBXHPNNejSpQsuuOACfP311wCA//znP6drJN26dUNBQQH27NmDvn37IisrC506dcLy5ctje8OC4Cq8kohqQER+DjO/EyTrTfBz2zCzmTx4PxG9C6AXgGWRFTcwpsH1wQfFXdOqlYi8NsQqSuwJ1iYW62du9+7dWLlyJVJSUnD06FEsX74c1atXx5IlS/DAAw/g7bffLrfP5s2bsXTpUhQUFKB9+/YYN25cuZjzL7/8Ehs2bEDz5s3Rp08ffPbZZ8jOzsadd96JZcuWoU2bNhg+fHjI8k2ZMgXdunXD/Pnz8cknn+DWW2/FunXr8NRTT+HZZ59Fnz59UFhYiFq1amHGjBn42c9+hgcffBAlJSUo8r+JccRN1A0BeAnAJmb+c5B89SHzav7cllYXQDVmLrC+Xw6ZjDnmjBihwq4oFUFFtoldf/31SElJAQAcOXIEI0eOxNatW0FEOHXqVMB9rrzySpxxxhk444wz0KRJE+zbtw8ZGRll8vTq1et0WlZWFnJzc1GvXj20bdv2dHz68OHDMWPGjKDlW7FixemXzaWXXor8/HwcPXoUffr0wb333osRI0bg2muvRUZGBnr27InRo0fj1KlTuOaaa5CVlRXVvQkHN66bPpCJfy8lonXW5woiGktEY235hgJYxMzHbGlNAawgoq8ArALwATNX1GTTiqLEgYpsE6tbt+7p75MnT8aAAQOwfv16vP/++46x5Gecccbp7ykpKQH9+27yRMOkSZPw4osv4vjx4+jTpw82b96Mvn37YtmyZWjRogVGjRqFV199NabnDEZIi56ZVwAIGbjJzLMAzPJL+xZA1wjLpihKJWTatLL9VoCKaRM7cuQIWrSQgL9Zs2bF/Pjt27fHt99+i9zcXGRmZuKNN94Iuc8ll1yCOXPmYPLkyfj000/RuHFjnHnmmdi+fTs6d+6Mzp07Y/Xq1di8eTNq166NjIwM3HHHHTh58iTWrl2LW2+9NebXEQjP9IxVFKViGDECmDEDaN0aIJLljBnxd51OnDgR999/P7p16xZzCxwAateujeeeew4DBw5Ejx49kJqaivr16wfdZ+rUqVizZg26dOmCSZMm4ZVXXgEAPP300+jUqRO6dOmCGjVqYNCgQfj000/RtWtXdOvWDW+88QYmTJgQ82twolLOGZudnc068YiiVBybNm3Ceeedl+hiJJzCwkLUq1cPzIzx48fj3HPPxT333JPoYpUj0O9FRGucOqWqRa8oimLxj3/8A1lZWejYsSOOHDmCO++8M9FFigk6eqWiKIrFPffcUykt+GhRi15RFMXjqNAriqJ4HBV6RVEUj6NCryiK4nFU6BVFSTgDBgzARx99VCbt6aefxrhx4xz36d+/P0wY9hVXXIHDhw+XyzN16lQ89dRTQc89f/58bNy48fT6Qw89hCVLloRT/IBUpuGMVegVRUk4w4cPx7x588qkzZs3z9XAYoCMOtmgQYOIzu0v9I888gh+8pOfRHSsyooKvaIoCWfYsGH44IMPTk8ykpubix9++AGXXHIJxo0bh+zsbHTs2BFTpkwJuH9mZiYOHDgAAJg2bRratWuHiy+++PRQxoDEyPfs2RNdu3bFddddh6KiIqxcuRLvvfcefvvb3yIrKwvbt2/HqFGj8NZbbwEAPv74Y3Tr1g2dO3fG6NGjcfLkydPnmzJlCrp3747OnTtj8+bNQa8v0cMZaxy9oihluPtuYN262B4zKwt4+mnn7Y0aNUKvXr2wcOFCDBkyBPPmzcMNN9wAIsK0adPQqFEjlJSU4LLLLsPXX3+NLl26BDzOmjVrMG/ePKxbtw7FxcXo3r07evToAQC49tprcccddwAAfv/73+Oll17Cr3/9a1x99dUYPHgwhg0bVuZYJ06cwKhRo/Dxxx+jXbt2uPXWW/H888/j7rvvBgA0btwYa9euxXPPPYennnoKL774ouP1JXo4Y7XoFUWpFNjdN3a3zZtvvonu3bujW7du2LBhQxk3iz/Lly/H0KFDUadOHZx55pm4+uqrT29bv349LrnkEnTu3Blz5szBhg0bgpZny5YtaNOmDdq1awcAGDlyJJYt802lce211wIAevTogdzc3KDHWrFiBW655RYAgYcznj59Og4fPozq1aujZ8+eePnllzF16lR88803SE1NDXpsN6hFryhKGYJZ3vFkyJAhuOeee7B27VoUFRWhR48e+O677/DUU09h9erVaNiwIUaNGuU4PHEoRo0ahfnz56Nr166YNWsWPv3006jKa4Y6jmaY40mTJuHKK6/EggUL0KdPH3z00UenhzP+4IMPMGrUKNx7771Rj3KpFr2iKJWCevXqYcCAARg9evRpa/7o0aOoW7cu6tevj3379mHhwoVBj9G3b1/Mnz8fx48fR0FBAd5///3T2woKCtCsWTOcOnUKc2zzHqampqKgoKDcsdq3b4/c3Fxs27YNAPDaa6+hX79+EV2bGc4YQMDhjH/3u9+hZ8+e2Lx5M3bs2IGmTZvijjvuwO233461a9dGdE47atErilJpGD58OIYOHXrahWOG9e3QoQNatmyJPn36BN2/e/fuuPHGG9G1a1c0adIEPXv2PL3tD3/4A3r37o309HT07t37tLjfdNNNuOOOOzB9+vTTjbAAUKtWLbz88su4/vrrUVxcjJ49e2Ls2LHlzukGM5dtly5dUKdOnTLDGS9duhTVqlVDx44dMWjQIMybNw9PPvkkatSogXr16sVkgpKQwxQTUUsAr0Jmi2IAM5j5Gb88/QH8C8B3VtI7zPyItW0ggGcApAB4kZkfD1UoHaZYUSoWHaY4uQh3mGI3Fn0xgPuYeS0RpQJYQ0SLmdm/RWQ5M5fpHUBEKQCeBfBTALsBrCai9wLsqyiKosSJkD56Zt7DzGut7wUANgFo4fL4vQBsY+ZvmflHAPMADIm0sIqiKEr4hNUYS0SZALoB+CLA5guJ6CsiWkhEHa20FgB22fLshvuXhKIoFUhlnG1OKU8kv5NroSeiegDeBnA3Mx/127wWQGtm7grgrwDmh1sQIhpDRDlElJOXlxfu7oqiREGtWrWQn5+vYl/JYWbk5+ejVq1aYe3nKuqGiGpARH4OM78T4ORHbd8XENFzRNQYwPcAWtqyZlhp5WDmGQBmANIY6/oKFEWJmoyMDOzevRtqZFV+atWqhYyMjLD2CSn0REQAXgKwiZn/7JDnLAD7mJmJqBekppAP4DCAc4moDUTgbwJwc1glVBQl7tSoUQNt2rRJdDEqLQcOAEuXAtdfn+iSRIYbi74PgFsAfENEZgSMBwC0AgBmfgHAMADjiKgYwHEAN7HUAYuJ6FcAPoKEV85k5uD9jhVFUSoZr70G3HsvkJ8PNGqU6NKET0ihZ+YVAChEnr8B+JvDtgUAFkRUOkVRlErAkSO+ZTIKvQ6BoCiKEoJjx2R51D8MJUlQoVcURQlBYaEsVegVRVE8ihF648JJNlToFUVRQqAWvaIoisdRH72iKIrHUYteURTF46iPXlEUxeOo60ZRFMXjqOtGURTF46jQK4qieJjSUqCoSL6r0CuKongQI/KANsYqiqJ4EuO2AdSiVxRF8SQm4qZOHRV6RVEUT2Is+ubNVegVRVE8iV3ojx8HTp1KbHkiQYVeURQlCEbomzWTZTJa9SGFnohaEtFSItpIRBuIaEKAPCOI6Gsi+oaIVhJRV9u2XCt9HRHlxPoCFEVR4onx0TdvLstkFHo3c8YWA7iPmdcSUSqANUS0mJk32vJ8B6AfMx8iokEAZgDobds+gJkPxK7YiqIoFYPddQN4VOiZeQ+APdb3AiLaBKAFgI22PCttu3wOICPG5VQURUkIXhD6sHz0RJQJoBuAL4Jkuw3AQts6A1hERGuIaEyQY48hohwiysnLywunWIqiKHHD33WTjJ2m3LhuAABEVA/A2wDuZuaA7zQiGgAR+ottyRcz8/dE1ATAYiLazMzL/Pdl5hkQlw+ys7M5jGtQFEWJG4WFABHQtKmse9aiJ6IaEJGfw8zvOOTpAuBFAEOYOd+kM/P31nI/gHcB9Iq20IqiKBVFYSFQty7QoIGse1LoiYgAvARgEzP/2SFPKwDvALiFmf9nS69rNeCCiOoCuBzA+lgUXFEUpSI4dkyEvn59WU9GoXfjuukD4BYA3xDROivtAQCtAICZXwDwEIA0AM/JewHFzJwNoCmAd6206gBeZ+YPY3oFiqIocaSwEKhXD6hdG0hJ8aiPnplXAKAQeW4HcHuA9G8BdC2/h6IoSnJghJ4IOPPM5LTotWesoihKEIyPHlChVxRF8STHjolFD6jQK4qieBLjugGkQVaFXlEUxWP4u26SsTFWhV5RFCUI6rpRFEXxOHbXjQq9oiiKxygpkclG1EevKIriUYqKZGn30SfjLFMq9IqiKA6YIYrtrhsg+ax6FXpFURQHVOgVRVE8jhF6u+sGUKFXFEXxDGbSEXtjLKBCryiK4hmcXDfJ1mlKhV5RFMUBdd0oiqJ4HH/XjQq9oiiKx/B33XjWR09ELYloKRFtJKINRDQhQB4ioulEtI2Iviai7rZtI4loq/UZGesLUBRFiRf+Qm9mmUo2oXczlWAxgPuYea01/+saIlrMzBtteQYBONf69AbwPIDeRNQIwBQA2QDY2vc9Zj4U06tQFEWJA8eOycxStWrJupllynONscy8h5nXWt8LAGwC0MIv2xAAr7LwOYAGRNQMwM8ALGbmg5a4LwYwMKZXoCiKEifs0wgaknFgs7B89ESUCaAbgC/8NrUAsMu2vttKc0pXFEWp9NhHrjR4WuiJqB6AtwHczcwxv0wiGkNEOUSUk5eXF+vDK4qihM2xY77QSkMyjmDpSuiJqAZE5Ocw8zsBsnwPoKVtPcNKc0ovBzPPYOZsZs5OT093UyxFUZS44mTRe85HT0QE4CUAm5j5zw7Z3gNwqxV9cwGAI8y8B8BHAC4nooZE1BDA5VaaoihKpccrrhs3UTd9ANwC4BsiWmelPQCgFQAw8wsAFgC4AsA2AEUAfmFtO0hEfwCw2trvEWY+GLviK4qixI/CQqBhw7JpnhR6Zl4BgELkYQDjHbbNBDAzotJ5mHXrgLlzgccfL9uiryhK5eHYMaBly7JpySj02jM2Qbz5JvB//5d8vj5FqUoEct3Ur598s0yp0CeIfftkuX9/YssRL2bOBK65JtGlUJTocPLRA8ll1avQJwivC/3SpcD778vkyoqSrAQKr1ShV1xjBN6rQn/gAFBaCmiXCCVZKS4GTpxQi16JAq9b9Ebg9+xJbDkUJVL8hyg2JOMIlir0DpgfOR4wq9ArSmXHaICT6yaZAilU6AOwfLnEzu7cGZ/jFxQAJ0/Kd68K/YEDslShV5IV/yGKDeq68Qjr10vo1ObN8Tm+seYBbwp9UZF8ABV6JXlRofc4e/fKMl4iZYSeyJtCb2+AVaFXkhX/+WINKvQewQj9Dz/E5/hG3M8+25tCb9w2gAq9krw4NcbWqZN8s0yp0AfAWNzxEnpz/M6dvSn0xqKvW1eFXklenFw3yTjLlAp9AOJt0e/bJ3+Wjh2B/HyJ1/USxqLv3FmF3sAMrFkjSyU5cBJ6IPnGu1GhD0BFCH1aGtC8uazbXR1ewFj0RuhV3ICVK4HsbODzzxNdEsUtTuGVgAp90mOPcY+nj75JE/kAZaNwvEBeHlC9OtChA/Djj8AhnQoeW7bIcseOxJZDcU8wiz7ZZplSoffj6FHp9lyrVvys0X37gKZNfULvNT/9gQNA48a+Gou6b3x9MnRIiOShsFAaXc84o/w29dEnOcZt07mzxNLn58f+HF4X+rw8EfpmzWRdhV6FPhkxA5oFmi9CXTdJjnGjdO8uy3i4b/xdN14U+vR0FXo7KvTJR6Ahig2eE3oimklE+4lovcP23xLROuuznohKiKiRtS2XiL6xtuXEuvDxwFj08RL6EyfkD9K0KdCggfiyvSb0Bw6o0PtjfPMq9MlDlRJ6ALMADHTayMxPMnMWM2cBuB/Af/zmhR1gbc+OrqgVgxH6bt1kGWuhNzWGpk2lStikifeE3rhuUlM1lh6Q4Zp37ZLvKvTJQ2Fh4IgbIPlmmQop9My8DIDbCb2HA5gbVYkSzL590gDTqZOsx1rojagbt43XhL64GDh4UCx6QKz6qi70eXm+QexU6JOHY8eCW/RA8lj1MfPRE1EdiOX/ti2ZASwiojVENCbE/mOIKIeIcvIS+DTs3SvWdu3aQKNG8bXoAe8J/UHLJFCh92H8882bq9AnE6FcN0AVFHoAVwH4zM9tczEzdwcwCMB4IurrtDMzz2DmbGbOTjcqkQBMRAwgD6YKfXgYIWvcWJYq9D7/fI8eEsWl0ysmB8FcN1VZ6G+Cn9uGmb+3lvsBvAugVwzPFxf27gXOOku+N28ee5EyQu9V140RerXofRiLPjtb+mUcdOsIVRJKMNdNss0yFROhJ6L6APoB+JctrS4RpZrvAC4HEDBypzLhL/Tx8NGnpoprCBChLyqK74xWFYkZzsEu9IWFvl6GVZGdO0Uw2rWTdXXfJAdect1UD5WBiOYC6A+gMRHtBjAFQA0AYOYXrGxDASxiZrtcNQXwLklvg+oAXmfmD2NX9NhTWipCbHfd7Nkj6dViVPexu4aAsrH0bdrE5hyJJJDrBpD7eO65iSlTotm5E2jVyvdbq9AnB26EPll6x4YUemYe7iLPLEgYpj3tWwBdIy1YIjh0SMKl7BZ9SYk8mHZxjgavC72x6FXofezYIUJvajkq9JWfU6dknCb10XsQE0Nvt+iB2LpvTK9Yg9d6x+blif+yRg1Z105TPotehT55cJp0xKBCn8SYhlK7RQ/EVuiDWfRewAx/YDD30rxEqxpFRVLLad1ahqYGVOiTgWAjVwLJN8uUCr0NI0bxEvriYgmvswu9EUWvCL0Z/sCQlibWfVW16E2P2Fat5D40bKhCnwwEG4seSL5ZplTobfi7bswyVkJ/4ICE19ldN3XqiNXgFaE3wx8YiOTFWVWF3sTQt2oly/R0FfpkIJRFDyTXeDcq9Db27QNq1pTBxgD5np4eO5Hy7yxl8FIsvb/rBqjasfQmhr51a1mq0CcHKvQexsTQ28efjmUsvdeFnrm86wZQoa9WzecGTE/3xm/tdYzQO7luABX6pMWMc2MnHkJvd92YdS88/AUFEpJmd90AKvTNm/uikNSiTw5CRd0AyTWdoAq9jX37fA2xhlgKvRFzr1r0/sMfGJo1k0boH3+s+DIlGhNDb0hPl1pPaWniyqSExq3rRhtjkxD78AeG5s3lBVBcHP3x9+2T+SdNDK6hSRMRyWR/+P07SxlMLH1VDLHcudPnnwdE6EtKgMOHY3+u4mLgf/+L/XG9yIYNwQ049dF7FKcesM2b+4ZGiBYTQ+8/B2WTJnL+Q4eiP0ciCWbRA1XPfWMmHPG36IH4uG9eew3o2NHnIlScGTwYmDjReXuo8EpAhT4pMdXpQBY9EBv3jX+vWINXOk2p0Jdl3z7pSl9RQv/ll2rVu+H4cSA3F9iyxTlPYaFM81mzpnOeZJplSoXewr+zlMEIfSxEyr9XrMErQh/KdVPVhN7E0Pu7bgB3Qj9+PPDEE+7PZ4QrN9f9PlWRb7+V5XffOecxA5r5177tJNMwCCr0Fv6dpQxGpGJh0Xtd6PPypA3C36/ZpIk8MFVN6E0MfaQW/T//KR+3GKEPJmAKsH27LPPzJVIsEMeOBXfbACr0SYn/ODcG41OPVuiZq4brJj29vBVUvbpcowq9e6E/dkzybNrkrpG+qMh3PhX64Gzb5vvudK+CDVFsUKFPQpws+urVJS1aoT90SPyngSz6tDQRx2QX+sRmbK4AACAASURBVAMHyrttDFUxln7nThEDMxsRIDWe1NTQQm9Eu6jIN15OMLZuFWMCUNdNKIxFD/jcOP6o0HuUfft84874E4tYeqdesYC8TNLSkl/oAw1/YKiKQr9jR1n/vMFNpym7WG/cGPpcxm3TubNa9KHYvt33uwSz6EO5bpJpOsGQQk9EM4loPxEFnAaQiPoT0REiWmd9HrJtG0hEW4hoGxFNimXBY02g4Q8MsRT6QK4bk57sQh9o+ANDVRR6Mw69P/EU+p/+VGoAyRAJkii2bQN695aalZPQB5sv1pBMs0y5sehnARgYIs9yZs6yPo8AABGlAHgWwCAA5wMYTkTnR1PYeBJo+ANDLITeqVeswQtC7z9ypZ1mzeRlV1JSsWVKJNEI/Y4dEtrXuLH46UOxZYtYqeefLz793bsjK7PXOXVK7u0558iMbuq6sWDmZQAimbe+F4BtzPwtM/8IYB6AIREcp0IINPyBoXlzeTCjsZKCuW6A5Bf6kyflDx/Moi8trTrjvBQWAgcPRue6adVKOkC5seg3bwbat/dNR6num8Ds3CltZWefLfdKG2PD40Ii+oqIFhJRRyutBQB7M9JuK61SEmj4A0Pz5tLQFU2Pw337ZBRDM8uQP8ku9Pn5sgxm0QNVx30TKOLGYITeNJ4GIjcXyMwUC33jxuB5mcWiV6EPjWmINRZ9bm7ge+smvDKZZpmKhdCvBdCambsC+CuA+ZEchIjGEFEOEeXkVbDZd+pU+Zmf7MSid+z+/fKAV3O4402ayPgnyTrwl1OvWIMKvY/0dPmdnWK4AXEvZGYC550nPuBg4wTt2SMWaPv2QMuWIj4q9IExQn/22UDbthLVFMjAcmPRJ9MsU1ELPTMfZeZC6/sCADWIqDGA7wG0tGXNsNKcjjODmbOZOTvdSS3ihPmhnSz6WHSacuosZTCNtMnq2lChL0sooQecf+vjx0XYjc8dCO6+MQ2xHTpIBFdGhoZYOrFtG1C7tvwfTe3H30//449i/IUSeiB5xruJWuiJ6CwiiVUhol7WMfMBrAZwLhG1IaKaAG4C8F6054sHTsMfGGJh0bsV+mR13zgNf2Aw9zaWQv/jj7EZVTQe7NwplrX579gJJfTmJWFcN0Bwod+8WZbt28symO+5qrN9u1jy1ao5u7ncDGhm8IzQE9FcAP8F0J6IdhPRbUQ0lojGWlmGAVhPRF8BmA7gJhaKAfwKwEcANgF4k5k3xOcyosOps5QhPV0e2mhdN06hlUDyC30oi75WLZmiMZZCf+utYvUuWxa7Y8aKHTvEsk5JKb8tlNCbMXIyM+UFWb9+8MibLVtElFpYLWAq9M5s3y5uG0DuL1D+XrkZotiQLEJfPVQGZh4eYvvfAPzNYdsCAAsiK1rF4TT8gSElRbapRe9MXp74LBs1cs4Ty1h6ZmDRIulxPGAA8PDDwP33BxbWROAUWgmEFnrjdmndWu6paZB1YssWoF07Xx+QzEy5zydOyAtWEZhF6C+/XNbr1pVnMhqhr18/OZ5Z7RmL0BY9EF0sfWGhNPp4WegPHBCRDya0sRT67dtF5J96CrjpJmDyZOBnP6s8k5v4Tzhix43QV6/uc/u4EfoOHXzrxiVhagaKsGePtH8Yix4IHEvvZr5YQ5VpjPUCe/fKD1a7tnOe5s0jF6lQvWIBOX/Nmskr9MGGPzDEUuhXr5blZZcBs2cDL74IrFwJZGUBS5bE5hyRUlIiHZacLPq6deW/Fsx106qV76V53nmS17SD2DFjqxv/PKAhlk6YwczOOceXFsjN5Wa+WEOyuG5U6BG8s5QhGos+VK9YQKrdoWLpd+2qvI2PwXrFGozQB4sJd8vq1eKW6NhR7t1ttwGrVkk/hcsvB6ZMic15ImHPHvmdnIQekJei02+dm1u2NmAaZAP56bdtk+sMJPQaeVMWe2iloW3b8s+VF330nhf6Q4eACROAZ55xzhNs+AND8+ZiUZ08GX4ZQvWKNQQT+u+/F0vk2WfDP39FEGycG0OzZhIpE4spE1etArp1A2rU8KV16iTpI0cCjzwCjBuXmHl4g4VWGoL1jjWdpQzBIm9MaKVd6Js1k9qhWvRl2b5dakn236VNG6mB2UcIDddHnwyzTHlW6JmBN9+Uau/06eLDdRLpYL1iDcZfGokPOBZC/8YbIpIffRT++SsCt64bIHo/enExsHYt0LNn+W116wIzZwKTJgF//7tY+hU9vo4ReicfPeCbEN6fkyelRmAX+pYt5boCWfRG6Nu186VVqybnVqEvy7Ztcl/txkGgWPpwwyuBym/Ve1Lod+0Crr4auPFGCTl74gnphbhoUeD8blw30XSaMuIdSgiDCf3cubJcsaLihYsZ+NWvgOXLA28vLZWexW5cN0D0fvqNG8WK6tUr8HYi4I9/lEicWbOAn/+8Yi0uI/QtWzrncbLod+2S+21/SVSrJo2tgSz6zZt9LwI7GmJZHntopSFQe0a4rhtAhb5CKSkB/vpXqep+8olEZHzxBXD33RLD/dZb5fc5cUJazd24boDIhH7fPqBhw+ATDQM+off3LW/dCuTkiAVbUACsWxd+GaJhwwZxGf3lL4G3Hz4s996tRR+t0JuG2EAWvYEIeOgh4PHHgXnz5KVfUcNL7Nghv3dqqnMeJ6E3fnW7RQ84R96YMW78ycxUH70/27aVbYgFAg8ZEW7UDaBCX2EcOgT06QPcdZcs168H7rvPN5P7kCHAv/5V/mEPFUNviFboQ71IABH6Eyd8fzTD3LkiXH+zeiv85z/hlyEaPvxQlkuWBBbLUJ2lDLES+lWrxDfq/9AG4ne/A55+Gnj3XeDaa+X+xptgoZWG9HSplRg3gSHQhOKACP3335cVFPtgZv60aSPtJv7/parKwYNikPhb9NWri8/e33VTo0ZowwzwCf3hw7ErazzwjNA3aCA/4uzZwMKFviqZYdgwsdw//rhseqjhDwxpafLjRyJSoXrFGgLF0jMDr78O9O0rroqzz654oV+4UKyeggIJYfQn1PAHhtRUGfEvFhZ9z57OA8T5M2EC8MILwAcfiEsv3pZ9sM5SBqdY+txcudcZGWXTzztPlnY//b59Ivz2GHqDhliWJVDEjcHfzeVmQDODGV/ojTeiL2M88YzQEwFz5gAjRpSdJWrOHKnGXnWVpD/xRNn93HSWAkRUmjWLv0UPlBX6devEarv5Zlnv10985RUVTVJYKOe77Tb5Qxvr3o5bi54o+lj6EyeAb74J7rYJxJ13AjNmAIsXSyN9PIlW6DMy5F7bCRR54z/GjZ2KDLEsLQVeegm44gp389smgkAx9IZohD4jA7jjDuAf/yg7F21lwzNCH4g5c4AxY3zVYWaxhl95xZfHresGiDyWPhqhnztXHvrrrpP1fv3ETbU+4MSOsWfpUmnIvOEG4OKLxbr3x4hVKIseiF7o162TqJtwhR4Abr9dolNeeCHy84fi6FGpxkcq9E7zzLZpIxOL2y36QKGVBqdxXGLNxo1A//5ybxculP9pRbjHwsWIcNu25be1bSvPnHGjuRmL3s7kyVLbf+ih0HkBCVyoaJ++p4X+wQdl6AF/Jk70fTcWvRvXSiRCf/KkPPiRuG5KS6UhceBA34Ql/frJsqLcNx9+KH/6iy8GBg0Cvv5afMV2jOvGzejSTkK/a5dEyPj7rP1ZtUqWkQg9kVj2n30Wvxelm9BKILhF798QC8jLvl27shb9li3Sw9bfzWOOX6dO/IT++HHg97+XnsgbNohF/+674lYbNy4+ndVKSgL3DnbD9u3y/Abq/e7v5grHogfkPz1hgrhYv/oqeN79+4EuXaSj3zffuD9HtHha6M1D54/dYt67V8ZocdPwEonQmwfZjUVvHn5Tvs8+EwEcbhtWrnVr+VSE0DOLlXbppWJNDhok6f7um7w8X7f+UNiF/vBhGbqgf3+5pl/8wjmyx7B6tRyjRYRzlY0cKdfy979Htn8o3HSWAgIL/alT8hINJPRA+cgb0xAbqK2CKH4hlosWAZ07A9OmyX9z82Zg9GjgmmvEqp01K/Yd+06eBAYPFus7kn4YgSJuDNEKPSDGY4MGYlw6UVoK3HKLWPQlJRI0snhxeOeJFE8LvdPDVq2ar8uzmxh6Q7Nm4jY5ftx9Gdx2lgKkS/+ZZ/qEfu5cEc+rry6br29fGZo33l38t26VP/9Aa2r4Tp1EYP3dN26GPzA0ayaNukOHyj254w4R/ocfBi64AHj55eDtD6Yh1t4OEw5pacD11wOvvhq69hAJxhccSuhTU8W4sAv97t1y7U61gfPPF4vf1FLNPLFOxDrEkhn4zW9k8LiUFAlseOWVsjW5KVOkPezuu2NnjBQXSxvVhx+KCD/9dPjHCBRDbzDunGiEvmFDifD64APp6xKIJ56Ql+Qzz0jNtE0badeYOTO8c0WCp4V+2jSpvtqpWVMeJvMndNMr1mBCLP1dD8zygAcKZXMzoJkdE0t/6pQ0Gg4ZUv5P16+fCIRpjIsXxnI3Qk8k3xcvLtsByc3wBwZjVa1cKVX81avlOiZPBsaPlzA3p/HljxwRKzYSt42dsWPFRzpvXnTH8Sc/H3jsMbF2Q/2niMrH0jvF0BvOO88XUnnyZPnBzPwxFn0sDAJmCVf+05/kd/vqK6np+VOtmkS+nXOOvFCdatVuKS2V2sI774jA33AD8Nxz4YUzHjsmz6yTRe/v5grXR2+46y753e+/v/w9X75c/uM33ijthhkZknbppRLoMHlynA03Zq50nx49enCsmD2buXVrZiJZvvQSc506zJddJuuArM+eHfpYH30k+ZctY/7qK+bp05mHDWNu0kTSmzRh/sc/mIuLffu8/LJs277dXXkvuoj50kuZFyyQ/f71r/J5tm6Vbc8/7+6YkTJoEHO7dmXT3nrLdw8MPXpIXjcUFzOvW8d86lT5bUVFzPXrM99yS+B9lyyRc3/0kbtzOVFaytyxI3PPntEdx5/hw5mrV2deu9Zd/qws5sGDfeszZwb/r6xfL9tnz/Z9nzPH+fh/+pPkyc93fw2BKC1lvu8+Odavfy3rodi8mfnMM5m7d5ffNdLzjhsn5/3DHyTtyy9lfdo098f5+mvZZ9485zwdOzJffbV8b9GC+bbbIivzc8/JuT74wJeWlyfHPOcc5iNHyub/8Uc5F8A8YgTziRORnZeZGUAOO2hqwkU90CeWQh+IXr3kyu0fN2L/zTeSt2ZN336tWokwPfssc58+kpaVxfzpp7LP449LWmGhu7Jdcw1zp05yzIYNmU+eLJ+ntJS5eXPmm24qv81OQYG8FNw8mP4UFTHXqsV8111l0w8fFjG7/35fmrkHsWDsWObateU8/jz2WGyEi5n5r3+VY+XkRH8sZuZ//lOO98gj7vf56U+Ze/f2rT/0kBgkgX5zZklPSWF+8EHmt9+W861Z43z8d94JnScUpaXMv/2tHGf8+PD+S++9J/vdckv4/8HSUuaJE2X/iRPL7j9oEHN6OvOxY+6O9e67cpzVq53zDB7M3LmzfK9fn3nChPDKazh5krltW+auXZlLSuQzaJBohpMBUFoqLy6AuX9/91rhT1RCD2AmgP0A1jtsHwHgawDfAFgJoKttW66Vvi5YIfw/8Rb6xo3LCz0gFn4wTpwQIR49mvmVV5hzc8tuLy0Vq6FVKzneddcxX389c9267ss2ZgxzgwbM9eox3367c76bbhKxD/YA/exnUo7mzeVhmzWLedcud+X48EPZd8GC8tv69pWXmaFOHeZ773V33FCsXi3nfeGF8tuuvZb57LNjc55Dh+SFcscd0R9r7175T2Vni4XmlptvFlEwjBzJnJERfJ/27ZmHDvUJQ0GBc961ayXPW2+5L5Od0lLm3/1OjvHLX0ZmMDz8sOzfsSPz5MlSm3NznEcflf3GjSuff9ky2fbXv7orw5NPSv6DB53z3HWXPHOlpWLIPPCAu2MHYvZsOd/rrzM/8YR8f/bZ0PvNmcP8i19Edp+Zoxf6vgC6BxH6iwA0tL4PAvCFbVsugMahzuH/ibfQBxJ5QKypWFBUJJZdnTpy3DZt3O/7+9/7yvPJJ875nn9e8mzdGni7cTPdcgvzDTeUfbm1aydWUiD3ieHuu8WiD1TtNpb1Dz+IVQVIWiwoLRXLKpBbJSMjdC0mHEaPlpewf3U6HEpL5eV/xhnMGzaEt++ECcypqb71fv2YL744+D5Dh4rY33qruAOCceiQ/DZPPhk8z9695V9QpaVSa3MSW7eUlMhLu18/5mrV5Hht2zL/5jfMn33GvGWLCPebb4or9MEHmW+80fffLSkJfNw+fcSgcvNiHTuWuVGj4Hn+8hc55+7dsvzjH8O+1NOUlDB36cLcrJnUwIYNi/z+hUPUrhsAmU5C75evIYDvbeuVUuiNbz5ciz5cdu0S/9vDD7vfZ/p0KUuzZmV9/f5s3Cj5Xnyx/LbiYvmjtWnj8/mVlIg19ac/MQ8cKPtOnep8/A4dpEYQiHXrZP+XX5ZaDSBtE7HCPHRff+1L27NH0v7859idZ9UqOeZzz0V+jFdfDS2mThir1fxGrVuLnzYYDz4o4tGtm7TlhKJBA3G5BOLQIRFA8/9PTWXOzJQ2lwsvlLQ773QW23DZt0/+J4MGMdeoEfgZTEmR//7ttwc3RP79b8n/yiuhz/uTn4i7Nhjz58vxFi6U5fTp4V2bP++/73upBXJDxoOKFPrfAHjRtv4dgLUA1gAYE2LfMQByAOS0atUqrjdk9uyyfna7j96/8dZNI20seeMNKc899wTPV1oqjb+BfOOzZskx5s513n/ECHmoPv+8/LbvvpP9//IX53M3ayY1hZwcyTt/fvDyhkNengiB/R4Yf+/y5bE7T2mpCGaXLpFZXLt2iT+3T5/gL2Un/v53uaZdu0TUjP89GMYtYNwpocjKYr7iisDbTPvRo49KDXTCBOaf/1zy9+7NPGlS7ETen8OH5b/+2mvMixbJS33/fvfnKy2V3+2880Lv06aNNJQHwzTY/t//yfKll9yVI1j5nn9eGqUrigoRegADAGwCkGZLa2EtmwD4CkBfN+eLt0XPLJaFeWAyMnwib9wt4TTSxpKNG0U87NasE8OGla+FFBXJ9fTsGfwBOHRIqr7nnFPez2vcQps2Oe//i1+ItWgsqxUrQpc3HIYNE3eTaZicPFmq/pE2VDlhxPa//w1vv9JSqfHUqePsPguFaSxdu9Z9zcj43QHmZ54JfY6hQ0UM/Tlxgvmss6RBOFl5/XW5D+++65zn5En53/z+98GPVVDAp91FgLyEko1gQh+TOHoi6gLgRQBDmDnfpDPz99ZyP4B3AThMFVHx3H67xKhXqybxsyNGBB4yoagoeG+3WHPeedIpq3Pn0Hn79pWxUcxYPoB0xti9G3jyyeCjOzZoIJ2Gtm8H7r237LYPP5RY7mAx2oMGSSzzv/8t627j6N1y220Sn//++7K+apV02IokvjkYw4dL56Vwxr8pLgYefVRm+3rySXfDJQfC3jvWxNCHGjqhfXtfZ7Fgv4+hTRs5tthbPmbPlj4k9uFAko3rr5fOTo89Vv76DDt2SCx+qN+oXj3p9GeGJQi3w1Slx+kNYP8giEUPoBWAbQAu8kuvCyDV9n0lgIFuzlcRFj2zNJ7NnOlbJyprzce6kTbWfPUVl/FT7t8vsctXXeX+GCaqwrheTp6U6IOxY4Pvd+iQuBoaNuSQEQ2RUFwsjY2DBon13KhR5LHNoRg7Vhqe3YRtLlkijcWARAFF49rYvFmOM3u2/IYA8//+F3q/Nm0k73ffhc5r2nz27vWllZRIg263bhXTSBhPXnhBrm/JksDbjc/djcuvZ0+fS9eERycTiMaiJ6K5AP4LoD0R7Sai24hoLBGNtbI8BCANwHNEtI6Icqz0pgBWENFXAFYB+ICZAwxymzjOP1/GVzE4dVs36WbI42rVZDlnTrxLGJxOnWScHtPL99FHpXfu44+7P8Yjj8jAVLffLhbeZ5/JMUxvWCcaNAAuvFBqHykpMhFILElJAUaNEqt5xQqZOCLaHrFOjB0rIy62ayeDnn3ySfnpGrdulRrgT34iQzi89ZZ83I6JH4hAFn2ooRMA+d/WquUub6Bx6d9/X3rXTpwY+VASlYWRI6U36mOPBd5uhqRwGv7ATtu2vrkKqqRFX9GfirLo/Qnmo68M/vtADBkifvatWyX+N5K48A0bxKK94grpHFOjBvPRo6H3M7HcTZuGf043bNsmx8/KkmU0HX9CsXixNNjVreu7pvHjmT/+WHqF1qghNZ3HHmM+fjw25ywpkVrR/fdLm0ezZu72++AD9+Gspgft66/70i66SKJrgkW1JBOmAfWXvyxfK7v7bnlO3dRcJk3yPdsV2YgaK6A9Y93jFHVTUSGZ4WK6uffrJ3/oH36I7Dimil+rFvOAAe72MQ2DnTpFdk439O8v5zjjjPA6I0XKsWMS033ddXIvjOtu9OjI720wmjaVUMJLL5WQxlhTWCjXYOLCV6yQdbedjZKBEyfkpVytmrj4nn3W9xK76ipfj9dQmIZ5E0+fbKjQx4Bg/vtEhmSa8EZAutBHSkmJryftE0+436dpU/cvhkh47TUp0wUXxO8cThw9KkMNrFsXv3N06iS1srZtQ4cARkp6uq+md/XVzGlpsY9eqgx89ZXPMOjShXnpUok4GjrU3f6LFvmepUOH4lrUuBBM6D09emUscfKHNmrkm8WKWZZjxlSc/z4rS4Y2btJEhpCNlGrVZIjgm2+WCCS3+8yaBUydGvl5Q3HttRINYSZcqUhSU+X8XbvG7xzp6TLCqZsJxSPFjGK5aRPw3nvAr34V++ilykCXLtK+8s9/SkTYgAFyzW7880DZ2ae8dn9U6F0SaMhjs+4UklkRjbcpKTIX6rx5IkzR0KyZlDGcST0GDpQwz3hRp448rA8/HL9zJJL0dJntqrjYeXjiaDEhlk89JfMbjB8fn/NUBoiAYcNk6OuHHxYj6JJL3O3bqpU8q2ecIVMDegkVepeMGCGC2rq1/Jlat5b1gwcD5zeWfUVY+jfeKNaLV2ncWB4+L5Ke7pvHIF5CbyYgee01Gds91n0eKiO1a8tsV0eOlJ+4x4kaNWSceK9Z84AKfViMGCEPTGmpLEeMcHbppKQkvvOVUvmxi248XTfFxRIy6t85TilL27YeDK2ECn3UOLl0/OOwDTt3Vr54fCVxVJTQA76epIoz11wj0/t5DRX6KHFy6Tg9tIluvFUqF0bomzZ1N7l6JPTqBVx+ucznqgRnwgTg+ecTXYrYo0IfAwK5dCpr461SuTBCHy9rHpBezB99JOMoKVUTFfo4EevGW30JeBMj9PFqiFUUAKie6AJ4mREjysekP/hg2dEmDaEab8eM8W03LwFzDiV5adJElir0SjxRi76CiaTxNtjwyWrpJzdpaTKQ2rBhiS6J4mVU6CuYcBtvW7USsQ9ERcbqK/GhWjUZCz9eI3MqCqBCnxDCabydNi2yWH219BVFMajQVxKcLP1gLwEnd08wS19fAIpS9VChr0QEsvRNejjuHidLf8IEjexRlKqIK6EnoplEtJ+I1jtsJyKaTkTbiOhrIupu2zaSiLZan5GxKnhVIxx3j5Oln58f3NUTbi1AXwyKkiQ4jV9s/wDoC6A7nOeNvQLAQgAE4AIAX1jpjQB8ay0bWt8bhjpfZRyPvrISaCx8p0lSnD5m30Db0tICz6w1blzlnHFLUaoqiHY8emZeBsChqw8AYAiAV63zfQ6gARE1A/AzAIuZ+SAzHwKwGECI2UiVcAjH0k9LC3yMYJE9TrWAGTO0IVhRkoVY+ehbANhlW99tpTmlK3HEyaf/zDPhR/Y4oQ3BipI8VJrGWCIaQ0Q5RJSTl5eX6OIkPYEs/Ugie5xqASkpzunaEKwolYtYCf33AFra1jOsNKf0cjDzDGbOZubs9KowM0KCCDeyx6kWMGaMNgQrStLg5Lz3/wDIhHNj7JUo2xi7in2Nsd9BGmIbWt8bhTqXNsZWLpwmP6+MDcHhlFVRvASCNMaSbA8OEc0F0B9AYwD7AEwBUMN6UbxARATgb5CG1iIAv2DmHGvf0QAesA41jZlfDnW+7OxszsnJCVkupfJhrHO79V6njoy1np9fPn/r1tIQ7OJveJqUlMA1h7Q04Pjx8uceORJ45ZXy6cZtpShegIjWMHN2wI1Ob4BEftSiT24CWc+zZztb4eHWAsL9pKQETm/d2rm8wdIVpTKCIBZ9wkU90EeF3psEE9RAL4G0tPCEO9wPkfO51T2kJBsq9EqlJ5xagJMIh/tiaN3auTbhtE+kHcj05aDEGxV6JWkJRyAjsc6JAgt6LN1DWmtQKgIVeqXKEK5AhmvRR+IeqohaQ7AXgL4cqgYq9IriQEW4h+Jda3B6MYRqBA/3pagvjMqNCr2iBCHe7qF41xqcPsHaIMKtNURam1AqDhV6RYkhkVjC8aw1OH2Iwq9NOJ0jktpEJPdKiRwVekVJMPGsNTi9GIJZ9PH+VFQjtL4wfKjQK0qSEYsXQ7Bt4dYaIqlNxLsROtYhrcn+0lChVxSPE27UTbjWdiS1iXg3QscypNULEU0q9IqilCMWFm8kQ1vEuxE6ktqEFyKaVOgVRYkbiWqEroiQVqdPRUU0hYMKvaIoCSGejdCxDGmtjBFNZtA9t6jQK4qSFMTK5VERbRDxjmgiCu/eqdArilLliHcbRLwjmtSiVxRFqSASFdGkPnpFUZRKTGWLunE7leBAAM8ASAHwIjM/7rf9LwAGWKt1ADRh5gbWthIA31jbdjLz1aHOp1MJKoqihEewqQSru9g5BcCzAH4KYDeA1UT0HjNvNHmY+R5b/l8D6GY7xHFmzoq08IqiKEp0VHORpxeAbcz8LTP/CGAegCFB8g8HMDcWhVMURVGix43QtwCwy7a+20orBxG1BtAGwCe25FpElENEnxPRNU4nIaIxVr6cvLw8F8VSFEVRrkRdQQAABF9JREFU3OBG6MPhJgBvMXOJLa215Te6GcDTRHR2oB2ZeQYzZzNzdnp6eoyLpSiKUnVxI/TfA2hpW8+w0gJxE/zcNsz8vbX8FsCnKOu/VxRFUeJMyKgbIqoO4H8ALoMI/GoANzPzBr98HQB8CKCNFeoDImoIoIiZTxJRYwD/BTDE3pDrcM48ADtClL0xgAMh8ngRve6qhV531SKa627NzAHdISGjbpi5mIh+BeAjSHjlTGbeQESPQOI237Oy3gRgHpd9c5wH4O9EVAqpPTweSuStc4b03RBRjlMokZfR665a6HVXLeJ13SGFHgCYeQGABX5pD/mtTw2w30oAnaMon6IoihIlsW6MVRRFUSoZySz0MxJdgASh11210OuuWsTlul0NgaAoiqIkL8ls0SuKoiguUKFXFEXxOEkn9EQ0kIi2ENE2IpqU6PLEEyKaSUT7iWi9La0RES0moq3WsmEiyxhriKglES0loo1EtIGIJljpXr/uWkS0ioi+sq77YSu9DRF9Yf3f3yCimokuazwgohQi+pKI/m2tV5XrziWib4hoHRHlWGkx/68nldDbRtIcBOB8AMOJ6PzEliquzAIw0C9tEoCPmflcAB9b616iGMB9zHw+gAsAjLd+Y69f90kAlzJzVwBZAAYS0QUAngDwF2Y+B8AhALclsIzxZAKATbb1qnLdADCAmbNs8fMx/68nldAj/JE0kxpmXgbgoF/yEACvWN9fAeA4UFwywsx7mHmt9b0A8vC3gPevm5m50FqtYX0YwKUA3rLSPXfdAEBEGQCuBPCitU6oAtcdhJj/15NN6F2PpOlhmjLzHuv7XgBNE1mYeEJEmZCxkb5AFbhuy32xDsB+AIsBbAdwmJmLrSxe/b8/DWAigFJrPQ1V47oBeZkvIqI1RDTGSov5f91Vz1ilcsLMTESejI8lonoA3gZwNzMfFSNP8Op1W6O+ZhFRAwDvAuiQ4CLFHSIaDGA/M68hov6JLk8CuJiZvyeiJgAWE9Fm+8ZY/deTzaIPZyRNr7KPiJoBgLXcn+DyxBwiqgER+TnM/I6V7PnrNjDzYQBLAVwIoIE1sCDgzf97HwBXE1EuxBV7KWTaUq9fN4Ayo/vuh7zceyEO//VkE/rVAM61WuRrQgZSey/EPl7jPQAjre8jAfwrgWWJOZZ/9iUAm5j5z7ZNXr/udMuSBxHVhkzduQki+MOsbJ67bma+n5kzmDkT8jx/wswj4PHrBgAiqktEqeY7gMsBrEcc/utJ1zOWiK6A+PTMSJrTElykuEFEcwH0hwxdug/AFADzAbwJoBVkKOcbmNm/wTZpIaKLASyHTChvfLYPQPz0Xr7uLpCGtxSIAfYmMz9CRG0hlm4jAF8C+Dkzn0xcSeOH5br5DTMPrgrXbV3ju9ZqdQCvM/M0IkpDjP/rSSf0iqIoSngkm+tGURRFCRMVekVRFI+jQq8oiuJxVOgVRVE8jgq9oiiKx1GhVxRF8Tgq9IqiKB7n/wHrt9UI0ir5sAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history[\"sparse_categorical_accuracy\"]\n",
        "val_acc = history.history[\"val_sparse_categorical_accuracy\"]\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9q87dNfMxn89"
      },
      "source": [
        "#FOURTH APPROACH: Feature extraction together with data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kheuxzbZxn8-"
      },
      "source": [
        "**Instantiating and freezing the VGG16 convolutional base**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdnfVTuhxn8-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75880781-faea-4699-ef08-6a2d7986b994"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "conv_base  = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False)\n",
        "conv_base.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UZiYD97xn9A"
      },
      "source": [
        "**Printing the list of trainable weights before and after freezing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1Kr1jwPxn9A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ebc0891-df62-49c6-c7ae-6fc4f785d098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable weights before freezing the conv base: 26\n"
          ]
        }
      ],
      "source": [
        "conv_base.trainable = True\n",
        "print(\"This is the number of trainable weights \"\n",
        "      \"before freezing the conv base:\", len(conv_base.trainable_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LUrNGXIxn9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40261417-3c5b-4011-bbfb-670efe87fefc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable weights after freezing the conv base: 0\n"
          ]
        }
      ],
      "source": [
        "conv_base.trainable = False\n",
        "print(\"This is the number of trainable weights \"\n",
        "      \"after freezing the conv base:\", len(conv_base.trainable_weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_TmaXlExn9B"
      },
      "source": [
        "**Adding a data augmentation stage and a classifier to the convolutional base**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Prt-CbEHxn9C"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = keras.applications.vgg16.preprocess_input(x)\n",
        "x = conv_base(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"sparse_categorical_accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"feature_extraction_with_data_augmentation.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=50,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "jhqmzi7t9pa-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c994fed-e30a-4acc-e572-6c4093e4b3cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "29/29 [==============================] - 11s 338ms/step - loss: 2.7605 - sparse_categorical_accuracy: 0.2475 - val_loss: 1.3809 - val_sparse_categorical_accuracy: 0.2232\n",
            "Epoch 2/50\n",
            "29/29 [==============================] - 9s 299ms/step - loss: 1.3866 - sparse_categorical_accuracy: 0.3152 - val_loss: 1.3842 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 3/50\n",
            "29/29 [==============================] - 9s 298ms/step - loss: 1.3857 - sparse_categorical_accuracy: 0.3163 - val_loss: 1.3820 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 4/50\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 1.3846 - sparse_categorical_accuracy: 0.3152 - val_loss: 1.3800 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 5/50\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 1.3792 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3782 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 6/50\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 1.3776 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3766 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 7/50\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 1.3763 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3756 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 8/50\n",
            "29/29 [==============================] - 9s 306ms/step - loss: 1.3773 - sparse_categorical_accuracy: 0.3152 - val_loss: 1.3745 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 9/50\n",
            "29/29 [==============================] - 9s 308ms/step - loss: 1.3743 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3738 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 10/50\n",
            "29/29 [==============================] - 9s 308ms/step - loss: 1.3735 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3730 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 11/50\n",
            "29/29 [==============================] - 9s 307ms/step - loss: 1.3728 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3722 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 12/50\n",
            "29/29 [==============================] - 9s 307ms/step - loss: 1.3722 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3718 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 13/50\n",
            "29/29 [==============================] - 9s 309ms/step - loss: 1.3716 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3712 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 14/50\n",
            "29/29 [==============================] - 9s 304ms/step - loss: 1.3711 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3707 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 15/50\n",
            "29/29 [==============================] - 9s 311ms/step - loss: 1.3707 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3704 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 16/50\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 1.3709 - sparse_categorical_accuracy: 0.3208 - val_loss: 1.3701 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 17/50\n",
            "29/29 [==============================] - 9s 306ms/step - loss: 1.3701 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3698 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 18/50\n",
            "29/29 [==============================] - 9s 309ms/step - loss: 1.3698 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3696 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 19/50\n",
            "29/29 [==============================] - 9s 302ms/step - loss: 1.3697 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3695 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 20/50\n",
            "29/29 [==============================] - 9s 302ms/step - loss: 1.3695 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3693 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 21/50\n",
            "29/29 [==============================] - 9s 319ms/step - loss: 1.3694 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3692 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 22/50\n",
            "29/29 [==============================] - 9s 307ms/step - loss: 1.3693 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3692 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 23/50\n",
            "29/29 [==============================] - 9s 308ms/step - loss: 1.3699 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3691 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 24/50\n",
            "29/29 [==============================] - 9s 311ms/step - loss: 1.3691 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3690 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 25/50\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 1.3690 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3689 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 26/50\n",
            "29/29 [==============================] - 9s 313ms/step - loss: 1.3690 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3688 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 27/50\n",
            "29/29 [==============================] - 9s 302ms/step - loss: 1.3701 - sparse_categorical_accuracy: 0.3163 - val_loss: 1.3688 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 28/50\n",
            "29/29 [==============================] - 9s 306ms/step - loss: 1.3688 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3688 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 29/50\n",
            "29/29 [==============================] - 9s 313ms/step - loss: 1.3688 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3688 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 30/50\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 1.3689 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3687 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 31/50\n",
            "29/29 [==============================] - 9s 301ms/step - loss: 1.3688 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3687 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 32/50\n",
            "29/29 [==============================] - 10s 334ms/step - loss: 1.3717 - sparse_categorical_accuracy: 0.3130 - val_loss: 1.3687 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 33/50\n",
            "29/29 [==============================] - 9s 306ms/step - loss: 1.3688 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3687 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 34/50\n",
            "29/29 [==============================] - 9s 313ms/step - loss: 1.3687 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3687 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 35/50\n",
            "29/29 [==============================] - 9s 312ms/step - loss: 1.3687 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3686 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 36/50\n",
            "29/29 [==============================] - 9s 315ms/step - loss: 1.3687 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3686 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 37/50\n",
            "29/29 [==============================] - 9s 306ms/step - loss: 1.3687 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3686 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 38/50\n",
            "29/29 [==============================] - 9s 296ms/step - loss: 1.3687 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3686 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 39/50\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 1.3687 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3686 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 40/50\n",
            "29/29 [==============================] - 9s 313ms/step - loss: 1.3687 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3686 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 41/50\n",
            "29/29 [==============================] - 9s 313ms/step - loss: 1.3687 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3686 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 42/50\n",
            "29/29 [==============================] - 9s 304ms/step - loss: 1.3687 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3686 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 43/50\n",
            "29/29 [==============================] - 9s 296ms/step - loss: 1.3687 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3686 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 44/50\n",
            "29/29 [==============================] - 9s 297ms/step - loss: 1.3687 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3686 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 45/50\n",
            "29/29 [==============================] - 9s 294ms/step - loss: 1.3686 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3686 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 46/50\n",
            "29/29 [==============================] - 9s 301ms/step - loss: 1.3687 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3686 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 47/50\n",
            "29/29 [==============================] - 9s 302ms/step - loss: 1.3687 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3686 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 48/50\n",
            "29/29 [==============================] - 9s 306ms/step - loss: 1.3686 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3686 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 49/50\n",
            "29/29 [==============================] - 9s 302ms/step - loss: 1.3687 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3686 - val_sparse_categorical_accuracy: 0.3170\n",
            "Epoch 50/50\n",
            "29/29 [==============================] - 9s 300ms/step - loss: 1.3687 - sparse_categorical_accuracy: 0.3174 - val_loss: 1.3686 - val_sparse_categorical_accuracy: 0.3170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omWu3HWmxn9E"
      },
      "source": [
        "**Evaluating the model on the test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwzREIF4xn9F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ce985b8-c157-4ee1-a5ac-3b36530f6ed5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 2s 312ms/step - loss: 1.3686 - sparse_categorical_accuracy: 0.3170\n",
            "Test accuracy: 0.317\n"
          ]
        }
      ],
      "source": [
        "test_model = keras.models.load_model(\n",
        "    \"feature_extraction_with_data_augmentation.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(validation_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdvzRLjzxn9G"
      },
      "source": [
        "#FIFTH APPROACH: Fine-tuning a pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpohKngrxn9H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3160fc28-5587-4c88-b95b-cf46b6031052"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_19 (InputLayer)       [(None, None, None, 3)]   0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "conv_base.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmZ9ZU69xn9H"
      },
      "source": [
        "**Freezing all layers until the fourth from the last**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tt5JZuvGxn9I"
      },
      "outputs": [],
      "source": [
        "conv_base.trainable = True\n",
        "for layer in conv_base.layers[:-4]:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiSUjK8Sxn9J"
      },
      "source": [
        "**Fine-tuning the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJoE2yUHxn9J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa774e5e-46d6-4ccb-f0b1-53dd6253d6d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "29/29 [==============================] - 12s 338ms/step - loss: 1.3812 - sparse_categorical_accuracy: 0.3396 - val_loss: 1.2948 - val_sparse_categorical_accuracy: 0.4107\n",
            "Epoch 2/30\n",
            "29/29 [==============================] - 9s 314ms/step - loss: 1.3583 - sparse_categorical_accuracy: 0.3374 - val_loss: 1.3008 - val_sparse_categorical_accuracy: 0.2991\n",
            "Epoch 3/30\n",
            "29/29 [==============================] - 9s 315ms/step - loss: 1.3167 - sparse_categorical_accuracy: 0.3618 - val_loss: 1.3398 - val_sparse_categorical_accuracy: 0.3661\n",
            "Epoch 4/30\n",
            "29/29 [==============================] - 11s 375ms/step - loss: 1.3311 - sparse_categorical_accuracy: 0.3685 - val_loss: 1.2710 - val_sparse_categorical_accuracy: 0.3929\n",
            "Epoch 5/30\n",
            "29/29 [==============================] - 10s 350ms/step - loss: 1.3109 - sparse_categorical_accuracy: 0.3718 - val_loss: 1.5279 - val_sparse_categorical_accuracy: 0.2589\n",
            "Epoch 6/30\n",
            "29/29 [==============================] - 10s 316ms/step - loss: 1.3054 - sparse_categorical_accuracy: 0.3607 - val_loss: 1.2513 - val_sparse_categorical_accuracy: 0.4107\n",
            "Epoch 7/30\n",
            "29/29 [==============================] - 9s 317ms/step - loss: 1.3173 - sparse_categorical_accuracy: 0.3696 - val_loss: 1.3199 - val_sparse_categorical_accuracy: 0.4196\n",
            "Epoch 8/30\n",
            "29/29 [==============================] - 10s 324ms/step - loss: 1.2841 - sparse_categorical_accuracy: 0.3740 - val_loss: 1.2503 - val_sparse_categorical_accuracy: 0.4107\n",
            "Epoch 9/30\n",
            "29/29 [==============================] - 10s 328ms/step - loss: 1.3152 - sparse_categorical_accuracy: 0.3618 - val_loss: 1.2212 - val_sparse_categorical_accuracy: 0.4196\n",
            "Epoch 10/30\n",
            "29/29 [==============================] - 9s 320ms/step - loss: 1.3068 - sparse_categorical_accuracy: 0.3818 - val_loss: 1.3298 - val_sparse_categorical_accuracy: 0.4241\n",
            "Epoch 11/30\n",
            "29/29 [==============================] - 9s 318ms/step - loss: 1.2883 - sparse_categorical_accuracy: 0.3907 - val_loss: 1.2233 - val_sparse_categorical_accuracy: 0.5089\n",
            "Epoch 12/30\n",
            "29/29 [==============================] - 9s 311ms/step - loss: 1.2772 - sparse_categorical_accuracy: 0.4107 - val_loss: 1.4536 - val_sparse_categorical_accuracy: 0.3438\n",
            "Epoch 13/30\n",
            "29/29 [==============================] - 9s 316ms/step - loss: 1.2856 - sparse_categorical_accuracy: 0.3718 - val_loss: 1.2309 - val_sparse_categorical_accuracy: 0.4330\n",
            "Epoch 14/30\n",
            "29/29 [==============================] - 9s 316ms/step - loss: 1.2898 - sparse_categorical_accuracy: 0.3929 - val_loss: 1.3489 - val_sparse_categorical_accuracy: 0.4062\n",
            "Epoch 15/30\n",
            "29/29 [==============================] - 10s 327ms/step - loss: 1.2664 - sparse_categorical_accuracy: 0.4073 - val_loss: 1.1880 - val_sparse_categorical_accuracy: 0.4688\n",
            "Epoch 16/30\n",
            "29/29 [==============================] - 9s 323ms/step - loss: 1.2485 - sparse_categorical_accuracy: 0.4162 - val_loss: 1.2420 - val_sparse_categorical_accuracy: 0.4420\n",
            "Epoch 17/30\n",
            "29/29 [==============================] - 10s 326ms/step - loss: 1.2594 - sparse_categorical_accuracy: 0.4195 - val_loss: 1.1789 - val_sparse_categorical_accuracy: 0.4554\n",
            "Epoch 18/30\n",
            "29/29 [==============================] - 10s 331ms/step - loss: 1.2582 - sparse_categorical_accuracy: 0.4018 - val_loss: 1.1702 - val_sparse_categorical_accuracy: 0.5179\n",
            "Epoch 19/30\n",
            "29/29 [==============================] - 9s 318ms/step - loss: 1.2655 - sparse_categorical_accuracy: 0.4184 - val_loss: 1.2609 - val_sparse_categorical_accuracy: 0.4375\n",
            "Epoch 20/30\n",
            "29/29 [==============================] - 9s 310ms/step - loss: 1.2301 - sparse_categorical_accuracy: 0.4295 - val_loss: 1.2683 - val_sparse_categorical_accuracy: 0.4732\n",
            "Epoch 21/30\n",
            "29/29 [==============================] - 9s 317ms/step - loss: 1.2233 - sparse_categorical_accuracy: 0.4317 - val_loss: 1.1783 - val_sparse_categorical_accuracy: 0.4821\n",
            "Epoch 22/30\n",
            "29/29 [==============================] - 9s 315ms/step - loss: 1.2418 - sparse_categorical_accuracy: 0.4195 - val_loss: 1.2777 - val_sparse_categorical_accuracy: 0.3393\n",
            "Epoch 23/30\n",
            "29/29 [==============================] - 9s 320ms/step - loss: 1.2176 - sparse_categorical_accuracy: 0.4107 - val_loss: 1.2147 - val_sparse_categorical_accuracy: 0.5268\n",
            "Epoch 24/30\n",
            "29/29 [==============================] - 9s 321ms/step - loss: 1.2316 - sparse_categorical_accuracy: 0.4340 - val_loss: 1.2129 - val_sparse_categorical_accuracy: 0.4509\n",
            "Epoch 25/30\n",
            "29/29 [==============================] - 9s 315ms/step - loss: 1.2431 - sparse_categorical_accuracy: 0.4329 - val_loss: 1.1821 - val_sparse_categorical_accuracy: 0.5000\n",
            "Epoch 26/30\n",
            "29/29 [==============================] - 11s 364ms/step - loss: 1.2345 - sparse_categorical_accuracy: 0.4173 - val_loss: 1.1564 - val_sparse_categorical_accuracy: 0.5446\n",
            "Epoch 27/30\n",
            "29/29 [==============================] - 9s 317ms/step - loss: 1.2286 - sparse_categorical_accuracy: 0.4084 - val_loss: 1.2656 - val_sparse_categorical_accuracy: 0.3705\n",
            "Epoch 28/30\n",
            "29/29 [==============================] - 9s 311ms/step - loss: 1.2104 - sparse_categorical_accuracy: 0.4329 - val_loss: 1.1946 - val_sparse_categorical_accuracy: 0.4911\n",
            "Epoch 29/30\n",
            "29/29 [==============================] - 9s 318ms/step - loss: 1.2382 - sparse_categorical_accuracy: 0.4539 - val_loss: 1.2038 - val_sparse_categorical_accuracy: 0.4821\n",
            "Epoch 30/30\n",
            "29/29 [==============================] - 9s 328ms/step - loss: 1.1765 - sparse_categorical_accuracy: 0.4606 - val_loss: 1.1248 - val_sparse_categorical_accuracy: 0.5402\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),\n",
        "              metrics=[\"sparse_categorical_accuracy\"])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"fine_tuning.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUbmNymrxn9K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51fa0e14-06ba-42d0-8d2c-6f7c1da368dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 4s 477ms/step - loss: 1.1925 - accuracy: 0.4777\n",
            "Test accuracy: 0.478\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.load_model(\"fine_tuning.keras\")\n",
        "test_loss, test_acc = model.evaluate(validation_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SIXTH APPROACH:ResNet50"
      ],
      "metadata": {
        "id": "rfaF6UVy5rW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50 = keras.applications.resnet\n",
        "conv_model = resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=(180,180,3))\n",
        "for layer in conv_model.layers:\n",
        "    layer.trainable = False\n",
        "x = keras.layers.Flatten()(conv_model.output)\n",
        "x = keras.layers.Dense(256, activation='relu')(x)\n",
        "x = keras.layers.Dense(256, activation='relu')(x)\n",
        "x = keras.layers.Dense(256, activation='relu')(x)\n",
        "predictions = keras.layers.Dense(4, activation='softmax')(x)\n",
        "full_model = keras.models.Model(inputs=conv_model.input, outputs=predictions)\n",
        "full_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyvmrcrWyWQc",
        "outputId": "65c757fd-5d29-4f20-df46-d514093b63ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 3s 0us/step\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 180, 180, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 186, 186, 3)  0           ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 90, 90, 64)   9472        ['conv1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 90, 90, 64)   256         ['conv1_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 90, 90, 64)   0           ['conv1_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 92, 92, 64)   0           ['conv1_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 45, 45, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 45, 45, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 45, 45, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 45, 45, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 45, 45, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 45, 45, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 45, 45, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 45, 45, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 45, 45, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 45, 45, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 45, 45, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 45, 45, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 45, 45, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 45, 45, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 45, 45, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 45, 45, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 45, 45, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 45, 45, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 45, 45, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 45, 45, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 45, 45, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 45, 45, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 45, 45, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 45, 45, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 45, 45, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 45, 45, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 45, 45, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 45, 45, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 45, 45, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 45, 45, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 45, 45, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 45, 45, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 45, 45, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 23, 23, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 23, 23, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 23, 23, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 23, 23, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 23, 23, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 23, 23, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 23, 23, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 23, 23, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 23, 23, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 23, 23, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 23, 23, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 23, 23, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 23, 23, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 23, 23, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 23, 23, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 23, 23, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 23, 23, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 23, 23, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 23, 23, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 23, 23, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 23, 23, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 23, 23, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 23, 23, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 23, 23, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 23, 23, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 23, 23, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 23, 23, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 23, 23, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 23, 23, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 23, 23, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 23, 23, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 23, 23, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 23, 23, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 23, 23, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 23, 23, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 23, 23, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 23, 23, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 23, 23, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 23, 23, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 23, 23, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 23, 23, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 23, 23, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 12, 12, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 12, 12, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 12, 12, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 12, 12, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 12, 12, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 12, 12, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 12, 12, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 12, 12, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 12, 12, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 12, 12, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 12, 12, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 12, 12, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 12, 12, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 12, 12, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 12, 12, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 12, 12, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 12, 12, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 12, 12, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 12, 12, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 12, 12, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 12, 12, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 12, 12, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 12, 12, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 12, 12, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 12, 12, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 12, 12, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 12, 12, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 12, 12, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 12, 12, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 12, 12, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 12, 12, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 12, 12, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 12, 12, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 12, 12, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 12, 12, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 12, 12, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 12, 12, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 12, 12, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 6, 6, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 6, 6, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 6, 6, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 6, 6, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 6, 6, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 6, 6, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 6, 6, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 6, 6, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 6, 6, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 6, 6, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 6, 6, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 6, 6, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 6, 6, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 6, 6, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 6, 6, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 6, 6, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 6, 6, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 6, 6, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 6, 6, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 6, 6, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 6, 6, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 6, 6, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 6, 6, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 6, 6, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 6, 6, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 6, 6, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)            (None, 73728)        0           ['conv5_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 256)          18874624    ['flatten_3[0][0]']              \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 256)          65792       ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 256)          65792       ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 4)            1028        ['dense_10[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 42,594,948\n",
            "Trainable params: 19,007,236\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer=keras.optimizers.Adamax(),\n",
        "                  metrics=['sparse_categorical_accuracy'])\n",
        "history = full_model.fit(\n",
        "    train_dataset, \n",
        "    validation_data = validation_dataset,\n",
        "    workers=10,\n",
        "    epochs=30\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auq_vfedzax8",
        "outputId": "0853cf79-165c-4821-aa94-be5fdcfe408f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "29/29 [==============================] - 13s 317ms/step - loss: 1.6982 - sparse_categorical_accuracy: 0.4162 - val_loss: 1.2659 - val_sparse_categorical_accuracy: 0.3750\n",
            "Epoch 2/30\n",
            "29/29 [==============================] - 9s 282ms/step - loss: 0.9649 - sparse_categorical_accuracy: 0.6082 - val_loss: 0.9348 - val_sparse_categorical_accuracy: 0.6384\n",
            "Epoch 3/30\n",
            "29/29 [==============================] - 9s 272ms/step - loss: 0.7707 - sparse_categorical_accuracy: 0.7159 - val_loss: 0.8704 - val_sparse_categorical_accuracy: 0.6161\n",
            "Epoch 4/30\n",
            "29/29 [==============================] - 9s 265ms/step - loss: 0.7720 - sparse_categorical_accuracy: 0.6848 - val_loss: 0.7288 - val_sparse_categorical_accuracy: 0.7321\n",
            "Epoch 5/30\n",
            "29/29 [==============================] - 10s 259ms/step - loss: 0.7606 - sparse_categorical_accuracy: 0.6815 - val_loss: 0.9016 - val_sparse_categorical_accuracy: 0.5848\n",
            "Epoch 6/30\n",
            "29/29 [==============================] - 10s 257ms/step - loss: 0.7225 - sparse_categorical_accuracy: 0.7137 - val_loss: 0.6920 - val_sparse_categorical_accuracy: 0.7054\n",
            "Epoch 7/30\n",
            "29/29 [==============================] - 8s 254ms/step - loss: 0.6439 - sparse_categorical_accuracy: 0.7603 - val_loss: 0.7649 - val_sparse_categorical_accuracy: 0.6964\n",
            "Epoch 8/30\n",
            "29/29 [==============================] - 11s 308ms/step - loss: 0.5952 - sparse_categorical_accuracy: 0.7814 - val_loss: 0.8771 - val_sparse_categorical_accuracy: 0.6473\n",
            "Epoch 9/30\n",
            "29/29 [==============================] - 10s 301ms/step - loss: 0.5561 - sparse_categorical_accuracy: 0.7802 - val_loss: 0.7911 - val_sparse_categorical_accuracy: 0.6875\n",
            "Epoch 10/30\n",
            "29/29 [==============================] - 10s 267ms/step - loss: 0.5242 - sparse_categorical_accuracy: 0.8058 - val_loss: 0.6943 - val_sparse_categorical_accuracy: 0.6786\n",
            "Epoch 11/30\n",
            "29/29 [==============================] - 10s 246ms/step - loss: 0.5499 - sparse_categorical_accuracy: 0.7869 - val_loss: 0.6525 - val_sparse_categorical_accuracy: 0.7188\n",
            "Epoch 12/30\n",
            "29/29 [==============================] - 10s 285ms/step - loss: 0.6226 - sparse_categorical_accuracy: 0.7469 - val_loss: 1.1456 - val_sparse_categorical_accuracy: 0.5714\n",
            "Epoch 13/30\n",
            "29/29 [==============================] - 9s 271ms/step - loss: 0.5388 - sparse_categorical_accuracy: 0.7980 - val_loss: 0.6430 - val_sparse_categorical_accuracy: 0.7009\n",
            "Epoch 14/30\n",
            "29/29 [==============================] - 10s 284ms/step - loss: 0.4741 - sparse_categorical_accuracy: 0.8091 - val_loss: 0.9811 - val_sparse_categorical_accuracy: 0.6071\n",
            "Epoch 15/30\n",
            "29/29 [==============================] - 9s 313ms/step - loss: 0.5359 - sparse_categorical_accuracy: 0.7869 - val_loss: 0.6483 - val_sparse_categorical_accuracy: 0.6920\n",
            "Epoch 16/30\n",
            "29/29 [==============================] - 9s 265ms/step - loss: 0.4637 - sparse_categorical_accuracy: 0.8213 - val_loss: 0.8079 - val_sparse_categorical_accuracy: 0.6875\n",
            "Epoch 17/30\n",
            "29/29 [==============================] - 9s 274ms/step - loss: 0.4480 - sparse_categorical_accuracy: 0.8357 - val_loss: 0.5822 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 18/30\n",
            "29/29 [==============================] - 9s 263ms/step - loss: 0.5682 - sparse_categorical_accuracy: 0.7725 - val_loss: 0.6632 - val_sparse_categorical_accuracy: 0.7009\n",
            "Epoch 19/30\n",
            "29/29 [==============================] - 10s 287ms/step - loss: 0.5355 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.6769 - val_sparse_categorical_accuracy: 0.7188\n",
            "Epoch 20/30\n",
            "29/29 [==============================] - 9s 244ms/step - loss: 0.5342 - sparse_categorical_accuracy: 0.8024 - val_loss: 1.1711 - val_sparse_categorical_accuracy: 0.5714\n",
            "Epoch 21/30\n",
            "29/29 [==============================] - 10s 278ms/step - loss: 0.6086 - sparse_categorical_accuracy: 0.7614 - val_loss: 0.6122 - val_sparse_categorical_accuracy: 0.7098\n",
            "Epoch 22/30\n",
            "29/29 [==============================] - 9s 277ms/step - loss: 0.4443 - sparse_categorical_accuracy: 0.8346 - val_loss: 0.6314 - val_sparse_categorical_accuracy: 0.7634\n",
            "Epoch 23/30\n",
            "29/29 [==============================] - 10s 270ms/step - loss: 0.3869 - sparse_categorical_accuracy: 0.8524 - val_loss: 0.6492 - val_sparse_categorical_accuracy: 0.7366\n",
            "Epoch 24/30\n",
            "29/29 [==============================] - 10s 270ms/step - loss: 0.5069 - sparse_categorical_accuracy: 0.7869 - val_loss: 0.7026 - val_sparse_categorical_accuracy: 0.7009\n",
            "Epoch 25/30\n",
            "29/29 [==============================] - 8s 258ms/step - loss: 0.4944 - sparse_categorical_accuracy: 0.8091 - val_loss: 0.5896 - val_sparse_categorical_accuracy: 0.7321\n",
            "Epoch 26/30\n",
            "29/29 [==============================] - 8s 243ms/step - loss: 0.4482 - sparse_categorical_accuracy: 0.8224 - val_loss: 0.8515 - val_sparse_categorical_accuracy: 0.7054\n",
            "Epoch 27/30\n",
            "29/29 [==============================] - 8s 257ms/step - loss: 0.4010 - sparse_categorical_accuracy: 0.8535 - val_loss: 0.7011 - val_sparse_categorical_accuracy: 0.7054\n",
            "Epoch 28/30\n",
            "29/29 [==============================] - 9s 249ms/step - loss: 0.3739 - sparse_categorical_accuracy: 0.8579 - val_loss: 0.6372 - val_sparse_categorical_accuracy: 0.7188\n",
            "Epoch 29/30\n",
            "29/29 [==============================] - 8s 257ms/step - loss: 0.4570 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.7079 - val_sparse_categorical_accuracy: 0.7098\n",
            "Epoch 30/30\n",
            "29/29 [==============================] - 10s 307ms/step - loss: 0.4563 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.7105 - val_sparse_categorical_accuracy: 0.6964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrU4eurRxn9K"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert MBA06_Module3_Assignment3_AnandMohan.ipynb"
      ],
      "metadata": {
        "id": "_EkDD_Brwa5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70be4db7-aef8-4c50-945f-557afd242a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook MBA06_Module3_Assignment3_AnandMohan.ipynb to html\n",
            "[NbConvertApp] Writing 621034 bytes to MBA06_Module3_Assignment3_AnandMohan.html\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9Tov9MLExn8V",
        "aefd_KZxxn80"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}