{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uf5_hCaQ52SH",
        "outputId": "a8bb85e5-2d8a-4b95-9944-252cc0640a6f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15598, done.\u001b[K\n",
            "remote: Counting objects: 100% (205/205), done.\u001b[K\n",
            "remote: Compressing objects: 100% (148/148), done.\u001b[K\n",
            "remote: Total 15598 (delta 98), reused 119 (delta 57), pack-reused 15393\u001b[K\n",
            "Receiving objects: 100% (15598/15598), 14.64 MiB | 24.57 MiB/s, done.\n",
            "Resolving deltas: 100% (10622/10622), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd '/content/yolov5'"
      ],
      "metadata": {
        "id": "h58bHDJpMzH6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r '/content/yolov5/requirements.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OoOEEtG57D7",
        "outputId": "afd2765b-e971-494b-d0e9-dca334c7968b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gitpython>=3.1.30\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 7)) (1.22.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 8)) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 9)) (8.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 11)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 12)) (2.27.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 13)) (1.10.1)\n",
            "Collecting thop>=0.1.1\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 15)) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 16)) (0.15.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 17)) (4.65.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 26)) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 27)) (0.12.2)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 41)) (67.7.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (4.39.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (23.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (1.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r /content/yolov5/requirements.txt (line 12)) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r /content/yolov5/requirements.txt (line 12)) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r /content/yolov5/requirements.txt (line 12)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r /content/yolov5/requirements.txt (line 12)) (1.26.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r /content/yolov5/requirements.txt (line 15)) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r /content/yolov5/requirements.txt (line 15)) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r /content/yolov5/requirements.txt (line 15)) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r /content/yolov5/requirements.txt (line 15)) (3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r /content/yolov5/requirements.txt (line 15)) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r /content/yolov5/requirements.txt (line 15)) (3.1.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->-r /content/yolov5/requirements.txt (line 15)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->-r /content/yolov5/requirements.txt (line 15)) (16.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r /content/yolov5/requirements.txt (line 26)) (2022.7.1)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->-r /content/yolov5/requirements.txt (line 15)) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->-r /content/yolov5/requirements.txt (line 15)) (1.3.0)\n",
            "Installing collected packages: smmap, gitdb, gitpython, thop\n",
            "Successfully installed gitdb-4.0.10 gitpython-3.1.31 smmap-5.0.0 thop-0.1.1.post2209072238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9Vi00oy6A-h",
        "outputId": "cb7777fe-5f01-4f05-ac16-dd3776048ee3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq '/content/drive/MyDrive/Colab_Notebooks/SECONDYEAR_TRIMESTER4_Module03_deep-learning-applications/DAY4_APPLICATION_OF_DEEP_LEARNING/YOLO_Custom_ObjectDetection/1144images_dataset.zip'"
      ],
      "metadata": {
        "id": "rjeaOh126FUx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python '/content/yolov5/train.py' --imgsz 640 --batch-size 16 --epochs 10 --data '/content/yolov5/data/1144images_dataset.yaml' --weights yolov5s.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBQ_mHpM6Lqa",
        "outputId": "b089094b-9a01-49f4-d62f-99ffcde92300"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/yolov5/data/1144images_dataset.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m /content/requirements.txt not found, check failed.\n",
            "YOLOv5 🚀 v7.0-155-g8ecc727 Python-3.10.11 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\n",
            "\n",
            "Transferred 349/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/1144images_dataset/labels/train... 662 images, 0 backgrounds, 0 corrupt: 100% 662/662 [00:02<00:00, 253.15it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/1144images_dataset/labels/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/1144images_dataset/labels/val... 166 images, 1 backgrounds, 0 corrupt: 100% 166/166 [00:00<00:00, 202.42it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/1144images_dataset/labels/val.cache\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.03 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to yolov5/runs/train/exp4/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1myolov5/runs/train/exp4\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      3.52G    0.05934     0.0367     0.1283         17        640: 100% 42/42 [00:52<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:04<00:00,  1.30it/s]\n",
            "                   all        166        348      0.492     0.0573     0.0441     0.0164\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      3.74G    0.06105    0.01642    0.07021         28        640: 100% 42/42 [00:51<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:04<00:00,  1.36it/s]\n",
            "                   all        166        348      0.708      0.125     0.0942     0.0545\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      3.74G    0.06523    0.01354    0.05127         20        640: 100% 42/42 [00:48<00:00,  1.16s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:04<00:00,  1.43it/s]\n",
            "                   all        166        348      0.574      0.223      0.196      0.115\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      3.74G    0.06471    0.01342    0.03777         18        640: 100% 42/42 [00:50<00:00,  1.19s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:05<00:00,  1.15it/s]\n",
            "                   all        166        348      0.817      0.219      0.256      0.142\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      3.74G    0.05983    0.01281    0.03268         16        640: 100% 42/42 [00:48<00:00,  1.16s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:05<00:00,  1.00it/s]\n",
            "                   all        166        348      0.635      0.341      0.298      0.136\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      3.74G    0.05586    0.01197    0.03001         18        640: 100% 42/42 [00:51<00:00,  1.22s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:05<00:00,  1.17it/s]\n",
            "                   all        166        348      0.816      0.283      0.367      0.214\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      3.74G    0.05129    0.01202    0.02704         26        640: 100% 42/42 [00:48<00:00,  1.16s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:03<00:00,  1.51it/s]\n",
            "                   all        166        348      0.623      0.416      0.427      0.244\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      3.74G    0.04676    0.01138    0.02389         23        640: 100% 42/42 [00:50<00:00,  1.19s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:04<00:00,  1.42it/s]\n",
            "                   all        166        348      0.786      0.404      0.451      0.264\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      3.74G    0.04181    0.01146    0.02249         21        640: 100% 42/42 [00:50<00:00,  1.19s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:04<00:00,  1.46it/s]\n",
            "                   all        166        348       0.81      0.411      0.481      0.296\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      3.74G    0.03755    0.01069    0.02201         18        640: 100% 42/42 [00:51<00:00,  1.22s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:04<00:00,  1.42it/s]\n",
            "                   all        166        348      0.846      0.403      0.489      0.319\n",
            "\n",
            "10 epochs completed in 0.158 hours.\n",
            "Optimizer stripped from yolov5/runs/train/exp4/weights/last.pt, 14.8MB\n",
            "Optimizer stripped from yolov5/runs/train/exp4/weights/best.pt, 14.8MB\n",
            "\n",
            "Validating yolov5/runs/train/exp4/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 6/6 [00:07<00:00,  1.23s/it]\n",
            "                   all        166        348      0.846      0.403      0.489      0.319\n",
            "            motorcycle        166          3          1          0      0.501      0.309\n",
            "         traffic light        166         14      0.417      0.357      0.496       0.32\n",
            "          fire hydrant        166          2          1          0      0.289      0.176\n",
            "             stop sign        166          1          1          0          0          0\n",
            "                  bear        166         20      0.891          1       0.99      0.623\n",
            "               giraffe        166          1          1          0          0          0\n",
            "              umbrella        166         11      0.548      0.727      0.786      0.551\n",
            "               handbag        166          1          1          0    0.00505    0.00303\n",
            "                   tie        166          2          1          0          0          0\n",
            "          baseball bat        166         11      0.634      0.545        0.6      0.443\n",
            "             surfboard        166          3      0.712      0.848      0.913      0.764\n",
            "            wine glass        166         39      0.897      0.923      0.968      0.727\n",
            "                   cup        166          1          1          0          0          0\n",
            "                  fork        166          1          1          0    0.00948    0.00758\n",
            "                 knife        166         46      0.694      0.978      0.934      0.628\n",
            "                  bowl        166          1          1          0    0.00343    0.00274\n",
            "                 apple        166          3          1          0     0.0893     0.0625\n",
            "              sandwich        166          1          1          0    0.00783    0.00705\n",
            "               hot dog        166         12      0.808      0.917      0.968      0.544\n",
            "                  cake        166          4          1      0.449      0.728      0.527\n",
            "                 couch        166         87      0.763      0.989      0.963      0.632\n",
            "                toilet        166          3          1      0.592      0.913      0.465\n",
            "                 mouse        166          2          1          0     0.0234     0.0109\n",
            "                remote        166          6      0.622      0.289      0.401       0.33\n",
            "                  sink        166          4      0.461       0.25      0.411      0.272\n",
            "          refrigerator        166          8      0.644      0.625      0.641      0.272\n",
            "                  book        166         20      0.915       0.75      0.764      0.353\n",
            "                 clock        166         13      0.854      0.769      0.911      0.639\n",
            "                  vase        166         11      0.513      0.672      0.586      0.357\n",
            "              scissors        166         17          1       0.42       0.76      0.536\n",
            "Results saved to \u001b[1myolov5/runs/train/exp4\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python '/content/yolov5/detect.py' --weights '/content/yolov5/runs/train/exp4/weights/best.pt' --source '/content/1144images_dataset/images/train/00002.png'"
      ],
      "metadata": {
        "id": "37XaKrHidTXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "971f5f88-5281-4ed0-972e-aecc93228757"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/exp4/weights/best.pt'], source=/content/1144images_dataset/images/train/00002.png, data=yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m /content/requirements.txt not found, check failed.\n",
            "YOLOv5 🚀 v7.0-155-g8ecc727 Python-3.10.11 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "image 1/1 /content/1144images_dataset/images/train/00002.png: 384x640 2 couchs, 61.2ms\n",
            "Speed: 0.5ms pre-process, 61.2ms inference, 1.8ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1myolov5/runs/detect/exp7\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq '/content/drive/MyDrive/Colab_Notebooks/SECONDYEAR_TRIMESTER4_Module03_deep-learning-applications/DAY4_APPLICATION_OF_DEEP_LEARNING/YOLO_Custom_ObjectDetection/CarsData_makesense_ai.zip'"
      ],
      "metadata": {
        "id": "DVtqushxl0AM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python '/content/yolov5/train.py' --imgsz 640 --batch-size 16 --epochs 10 --data '/content/yolov5/data/CarsData_makesense_ai.yaml' --weights yolov5s.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54ed666b-1f54-47d1-f23d-079c534b1490",
        "id": "VQQEo9YXl0AP"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/yolov5/data/CarsData_makesense_ai.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m /content/requirements.txt not found, check failed.\n",
            "YOLOv5 🚀 v7.0-155-g8ecc727 Python-3.10.11 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 16.1MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 138MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/CarsData/labels/train... 174 images, 30 backgrounds, 0 corrupt: 100% 204/204 [00:00<00:00, 353.31it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/CarsData/labels/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/CarsData/labels/val... 71 images, 17 backgrounds, 0 corrupt: 100% 88/88 [00:00<00:00, 133.15it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/CarsData/labels/val.cache\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.94 anchors/target, 0.997 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to yolov5/runs/train/exp2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1myolov5/runs/train/exp2\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      3.46G     0.1151    0.03538          0         34        640: 100% 13/13 [00:17<00:00,  1.31s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:08<00:00,  2.72s/it]\n",
            "                   all         88        123       0.08      0.268     0.0443     0.0098\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      3.67G     0.0944    0.03614          0         38        640: 100% 13/13 [00:13<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:02<00:00,  1.42it/s]\n",
            "                   all         88        123     0.0805      0.285     0.0536      0.012\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      3.67G    0.08195    0.03591          0         32        640: 100% 13/13 [00:16<00:00,  1.27s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:01<00:00,  1.83it/s]\n",
            "                   all         88        123      0.343      0.569      0.284     0.0663\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      3.67G    0.07367    0.02961          0         30        640: 100% 13/13 [00:17<00:00,  1.36s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:01<00:00,  1.62it/s]\n",
            "                   all         88        123      0.352      0.525      0.392      0.143\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      3.67G    0.06721    0.02912          0         30        640: 100% 13/13 [00:16<00:00,  1.24s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:01<00:00,  1.88it/s]\n",
            "                   all         88        123      0.458      0.488      0.464      0.164\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      3.67G    0.06818    0.02585          0         24        640: 100% 13/13 [00:19<00:00,  1.49s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:02<00:00,  1.40it/s]\n",
            "                   all         88        123       0.31      0.463      0.288     0.0777\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      3.67G    0.06496    0.02526          0         38        640: 100% 13/13 [00:16<00:00,  1.28s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:01<00:00,  1.98it/s]\n",
            "                   all         88        123      0.511      0.561      0.522      0.182\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      3.67G    0.05799    0.02536          0         25        640: 100% 13/13 [00:18<00:00,  1.43s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:02<00:00,  1.17it/s]\n",
            "                   all         88        123      0.447      0.561      0.428      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      3.67G    0.05757    0.02395          0         47        640: 100% 13/13 [00:16<00:00,  1.30s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:01<00:00,  2.28it/s]\n",
            "                   all         88        123      0.538      0.667      0.584      0.212\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      3.67G    0.05261    0.02312          0         41        640: 100% 13/13 [00:18<00:00,  1.39s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:01<00:00,  1.53it/s]\n",
            "                   all         88        123      0.714      0.724      0.726      0.285\n",
            "\n",
            "10 epochs completed in 0.060 hours.\n",
            "Optimizer stripped from yolov5/runs/train/exp2/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from yolov5/runs/train/exp2/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating yolov5/runs/train/exp2/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.38s/it]\n",
            "                   all         88        123      0.714      0.724      0.727      0.285\n",
            "Results saved to \u001b[1myolov5/runs/train/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python '/content/yolov5/detect.py' --weights '/content/yolov5/runs/train/exp2/weights/best.pt' --source '/content/CarsData/images/val/00022.png'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "109bc867-fb15-4095-9eaa-11460f865e66",
        "id": "avIjAUYil0AS"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/exp2/weights/best.pt'], source=/content/CarsData/images/val/00022.png, data=yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m /content/requirements.txt not found, check failed.\n",
            "YOLOv5 🚀 v7.0-155-g8ecc727 Python-3.10.11 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/1 /content/CarsData/images/val/00022.png: 384x640 3 cars, 61.6ms\n",
            "Speed: 0.5ms pre-process, 61.6ms inference, 1.9ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1myolov5/runs/detect/exp3\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to html Yolov5ObjectDetectionAlgorithm.ipynb"
      ],
      "metadata": {
        "id": "EGQH_-fXaAKP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc998479-0728-415e-a0cc-f0f3c92ded36"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook Yolov5ObjectDetectionAlgorithm.ipynb to html\n",
            "[NbConvertApp] Writing 620377 bytes to Yolov5ObjectDetectionAlgorithm.html\n"
          ]
        }
      ]
    }
  ]
}