# -*- coding: utf-8 -*-
"""FB_bart-large-mnli_zero-shot_ecommerce_reviews.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Fk5EinVrkJjuJO0nD_-5jueCne8x4bVV
"""

!pip install transformers

from transformers import pipeline

"""#zero-shot sequence classifiers

Yin et al. proposed a method for using pre-trained NLI models as a ready-made zero-shot sequence classifiers. The method works by posing the sequence to be classified as the NLI premise and to construct a hypothesis from each candidate label.
"""

classifier = pipeline("zero-shot-classification",model="facebook/bart-large-mnli")

"""#zero-shot classification method:
It is surprisingly effective in many cases, particularly when used with larger pre-trained models like BART and Roberta. 

Here,we are using this model for zero-shot classification with Hugging Face's built-in pipeline
"""

import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/SECONDYEAR_TRIMESTER4_Module03_deep-learning-applications/ecommerce_reviews.csv')

df.dropna(inplace=True)

df.head(5)

df.shape

ecommerce_db = df.sample(frac =.002)

ecommerce_db.shape

ecommerce_db['Title'].unique()

ecommerce_db.head(5)

features = ['Review Text','Title']
ecommerce_db=ecommerce_db[features]

ecommerce_db.head(5)

sequences=ecommerce_db['Review Text']

Score_list = ecommerce_db['Title'].tolist()
genlist=[]
for k in range(0,26):
  x = Score_list[k].split(",")
  for i in x:
    genlist.append(i)
set_Genre = set(genlist)
genre = (list(set_Genre))

"""#Applying Zero Shot Text Classification Model on IMDB-Movie-Data Dataset:

we will collect first 100 rows of ecommerce_reviews Dataset and use Zero Shot Text Classification Model on the “Review Text” Field to predict the “Genre” Labels.
"""

print(genre)

sequences[0:5]

"""#predicting the “Genre” Labels"""

x=[]
j=0
for i in sequences:
  x.append(classifier(i,genre,multi_label=True))
  print(x[j])
  j=j+1
with open("classification_100.txt","w")as file1:
  file1.write(str(x))
file1.close()

"""# Evaluating prediction probabilities for the first five sequences:

predicting the “Genre” Labels,we are listing all scores of different labels for first five sequences and comparing with what is available in Genre_list.we get prediction probabilities of quite many labels as higher than 45% and mostly in the range of 70-90% which is quite satisfactory. 
"""

for i in range(0,5):
  print(x[i]['sequence'])
  print("Score_list:",genre)
  loop_len=len(x[i]['labels'])
  for j in range(0,loop_len):
    if(x[i]['scores'][j]<0.20):
      continue
    print(x[i]['labels'][j],'.....',x[i]['scores'][j])

"""# **CLASSIFICATION PROBLEM**"""

df.head(5)

features = ['Review Text','Rating']
df=df[features]

df.head()

df['Rating'].unique()

df.Rating = df.Rating.replace(2,1)

df['Rating'].unique()

df.head()

#Build the bow vector
from sklearn.feature_extraction.text import CountVectorizer
bow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=145, stop_words='english')
x_bow = bow_vectorizer.fit_transform(df["Review Text"])
#print(bow_vectorizer.get_feature_names())
print(x_bow.toarray())

# splitting data into training and validation set
from sklearn.model_selection import train_test_split
xtrain, xtest, ytrain, ytest = train_test_split(x_bow, df['Rating'], random_state=42, test_size=0.3)

xtrain = xtrain.toarray()
xtest = xtest.toarray()

xtrain.shape

ytrain.shape

# create model
from keras.models import Sequential
from keras.layers import Dense
from keras.models import model_from_json
model2=Sequential()
model2.add(Dense(50,input_dim=145,activation='relu'))
model2.add(Dense(8,activation='relu'))
model2.add(Dense(8,activation='relu'))
model2.add(Dense(1,activation='sigmoid'))

#Compile model
model2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

x_val = xtrain[:3000]
partial_x_train = xtrain[3000:]
y_val = ytrain[:3000]
partial_y_train = ytrain[3000:]

history = model2.fit(partial_x_train,
                    partial_y_train,
                    epochs=20,
                    batch_size=8,
                    validation_data=(x_val, y_val))

"""# **Plotting the training and validation accuracy**"""

import matplotlib.pyplot as plt
history_dict = history.history
loss_values = history_dict["loss"]
val_loss_values = history_dict["val_loss"]
epochs = range(1, len(loss_values) + 1)

plt.clf()
acc = history_dict["accuracy"]
val_acc = history_dict["val_accuracy"]
plt.plot(epochs, acc, "bo", label="Training acc")
plt.plot(epochs, val_acc, "b", label="Validation acc")
plt.title("Training and validation accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

!jupyter nbconvert --to html FB_bart-large-mnli_zero-shot_ecommerce_reviews.ipynb