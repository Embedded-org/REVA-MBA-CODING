{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sAJn9q5kwM1e"
      },
      "outputs": [],
      "source": [
        "#import required libraries\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Load the file\n",
        "# load text and covert to lowercase\n",
        "filename = \"wonderland.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()\n",
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n"
      ],
      "metadata": {
        "id": "jfGYWX1qwYKE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Summarize the Dataset\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)\n",
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)\n",
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXLYN-Yqwv7k",
        "outputId": "47a94061-6e6d-4bb2-e8e4-a637d2f00917"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters:  163781\n",
            "Total Vocab:  59\n",
            "Total Patterns:  163681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "metadata": {
        "id": "sMZm9lRyw8I5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the model\n",
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8grajQNxAhS",
        "outputId": "c89a03c3-265a-441b-b935-b06f45603568"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1278/1279 [============================>.] - ETA: 0s - loss: 2.9849\n",
            "Epoch 1: loss improved from inf to 2.98490, saving model to weights-improvement-01-2.9849.hdf5\n",
            "1279/1279 [==============================] - 25s 14ms/step - loss: 2.9849\n",
            "Epoch 2/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.8009\n",
            "Epoch 2: loss improved from 2.98490 to 2.80086, saving model to weights-improvement-02-2.8009.hdf5\n",
            "1279/1279 [==============================] - 17s 13ms/step - loss: 2.8009\n",
            "Epoch 3/20\n",
            "1278/1279 [============================>.] - ETA: 0s - loss: 2.7139\n",
            "Epoch 3: loss improved from 2.80086 to 2.71382, saving model to weights-improvement-03-2.7138.hdf5\n",
            "1279/1279 [==============================] - 17s 13ms/step - loss: 2.7138\n",
            "Epoch 4/20\n",
            "1276/1279 [============================>.] - ETA: 0s - loss: 2.6428\n",
            "Epoch 4: loss improved from 2.71382 to 2.64295, saving model to weights-improvement-04-2.6430.hdf5\n",
            "1279/1279 [==============================] - 17s 13ms/step - loss: 2.6430\n",
            "Epoch 5/20\n",
            "1278/1279 [============================>.] - ETA: 0s - loss: 2.5839\n",
            "Epoch 5: loss improved from 2.64295 to 2.58389, saving model to weights-improvement-05-2.5839.hdf5\n",
            "1279/1279 [==============================] - 17s 13ms/step - loss: 2.5839\n",
            "Epoch 6/20\n",
            "1276/1279 [============================>.] - ETA: 0s - loss: 2.5279\n",
            "Epoch 6: loss improved from 2.58389 to 2.52777, saving model to weights-improvement-06-2.5278.hdf5\n",
            "1279/1279 [==============================] - 17s 14ms/step - loss: 2.5278\n",
            "Epoch 7/20\n",
            "1276/1279 [============================>.] - ETA: 0s - loss: 2.4781\n",
            "Epoch 7: loss improved from 2.52777 to 2.47801, saving model to weights-improvement-07-2.4780.hdf5\n",
            "1279/1279 [==============================] - 17s 13ms/step - loss: 2.4780\n",
            "Epoch 8/20\n",
            "1276/1279 [============================>.] - ETA: 0s - loss: 2.4287\n",
            "Epoch 8: loss improved from 2.47801 to 2.42841, saving model to weights-improvement-08-2.4284.hdf5\n",
            "1279/1279 [==============================] - 17s 14ms/step - loss: 2.4284\n",
            "Epoch 9/20\n",
            "1277/1279 [============================>.] - ETA: 0s - loss: 2.3869\n",
            "Epoch 9: loss improved from 2.42841 to 2.38678, saving model to weights-improvement-09-2.3868.hdf5\n",
            "1279/1279 [==============================] - 17s 13ms/step - loss: 2.3868\n",
            "Epoch 10/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.3481\n",
            "Epoch 10: loss improved from 2.38678 to 2.34808, saving model to weights-improvement-10-2.3481.hdf5\n",
            "1279/1279 [==============================] - 17s 13ms/step - loss: 2.3481\n",
            "Epoch 11/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.3106\n",
            "Epoch 11: loss improved from 2.34808 to 2.31060, saving model to weights-improvement-11-2.3106.hdf5\n",
            "1279/1279 [==============================] - 17s 13ms/step - loss: 2.3106\n",
            "Epoch 12/20\n",
            "1276/1279 [============================>.] - ETA: 0s - loss: 2.2746\n",
            "Epoch 12: loss improved from 2.31060 to 2.27459, saving model to weights-improvement-12-2.2746.hdf5\n",
            "1279/1279 [==============================] - 17s 13ms/step - loss: 2.2746\n",
            "Epoch 13/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.2427\n",
            "Epoch 13: loss improved from 2.27459 to 2.24270, saving model to weights-improvement-13-2.2427.hdf5\n",
            "1279/1279 [==============================] - 17s 13ms/step - loss: 2.2427\n",
            "Epoch 14/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.2098\n",
            "Epoch 14: loss improved from 2.24270 to 2.20982, saving model to weights-improvement-14-2.2098.hdf5\n",
            "1279/1279 [==============================] - 17s 13ms/step - loss: 2.2098\n",
            "Epoch 15/20\n",
            "1277/1279 [============================>.] - ETA: 0s - loss: 2.1802\n",
            "Epoch 15: loss improved from 2.20982 to 2.18044, saving model to weights-improvement-15-2.1804.hdf5\n",
            "1279/1279 [==============================] - 17s 13ms/step - loss: 2.1804\n",
            "Epoch 16/20\n",
            "1278/1279 [============================>.] - ETA: 0s - loss: 2.1524\n",
            "Epoch 16: loss improved from 2.18044 to 2.15236, saving model to weights-improvement-16-2.1524.hdf5\n",
            "1279/1279 [==============================] - 17s 13ms/step - loss: 2.1524\n",
            "Epoch 17/20\n",
            "1277/1279 [============================>.] - ETA: 0s - loss: 2.1281\n",
            "Epoch 17: loss improved from 2.15236 to 2.12802, saving model to weights-improvement-17-2.1280.hdf5\n",
            "1279/1279 [==============================] - 17s 13ms/step - loss: 2.1280\n",
            "Epoch 18/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.0966\n",
            "Epoch 18: loss improved from 2.12802 to 2.09665, saving model to weights-improvement-18-2.0966.hdf5\n",
            "1279/1279 [==============================] - 17s 13ms/step - loss: 2.0966\n",
            "Epoch 19/20\n",
            "1277/1279 [============================>.] - ETA: 0s - loss: 2.0734\n",
            "Epoch 19: loss improved from 2.09665 to 2.07363, saving model to weights-improvement-19-2.0736.hdf5\n",
            "1279/1279 [==============================] - 17s 13ms/step - loss: 2.0736\n",
            "Epoch 20/20\n",
            "1278/1279 [============================>.] - ETA: 0s - loss: 2.0490\n",
            "Epoch 20: loss improved from 2.07363 to 2.04909, saving model to weights-improvement-20-2.0491.hdf5\n",
            "1279/1279 [==============================] - 17s 13ms/step - loss: 2.0491\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efd16f638b0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generating Text with the trained model\n",
        "# load the network weights\n",
        "filename = \"weights-improvement-20-2.0491.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "#reverse mapping from id to chars\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "import sys\n",
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfRwdvfWxK-H",
        "outputId": "d09fd166-5d8f-4dcf-a930-3c5d979d11fa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed:\n",
            "\" .  contributions to the project gutenberg\n",
            "literary archive foundation are tax deductible to the full \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print (\"\\nDone.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H82-iWHPxQDc",
        "outputId": "4e679267-fc66-4ded-85d6-95528dc12eda"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " project gutenberg-tm electronic works  too cro droations oo the frrl an ios fortei an the frul an toe wooke th the workd the whs so aea note a ait    'i con't know ie ' said alice, ''what i vonn th toe to teee to tee ' she said to herself, 'and the thit hid the douso, and the coumd sot to the theet hireed ''and the whit si the toote of the couse   the horphon ses toen in the corre of the coure  ' \n",
            "'that wou dad tou to tetee toe to tee toees '                    whil woe too e sone \n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to html Keras_LSTM_text_generation.ipynb"
      ],
      "metadata": {
        "id": "qHnNyV3xx6Oj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}